{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWa0BvJHEdDb"
      },
      "source": [
        "# Creating a Placement Algorithm\n",
        "\n",
        "This tutorial demonstrates how we can create a simple placement algorithm on EdgeSimPy.\n",
        "\n",
        "Let's start by importing the EdgeSimPy modules:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EdgeSimPy Import Debugging Script\n",
        "\n",
        "# Explicit dependency installation\n",
        "!pip install rich\n",
        "!pip install rich --upgrade\n",
        "!pip install networkx==2.6.2\n",
        "!pip install matplotlib pandas numpy\n",
        "!pip install git+https://github.com/EdgeSimPy/EdgeSimPy.git@v1.1.0\n",
        "\n",
        "# Python and package information\n",
        "!python --version\n",
        "!pip list | grep -E \"networkx|edge_sim_py\"\n",
        "\n",
        "# Comprehensive import and debugging script\n",
        "import sys\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "def print_module_structure(module_name):\n",
        "    \"\"\"\n",
        "    Recursively print the structure of a module\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Module Structure for {module_name} ---\")\n",
        "    try:\n",
        "        # Import the module\n",
        "        module = importlib.import_module(module_name)\n",
        "\n",
        "        # Get the module's file path\n",
        "        module_file = getattr(module, '__file__', 'No __file__ attribute')\n",
        "        print(f\"Module file path: {module_file}\")\n",
        "\n",
        "        # Get the module's directory\n",
        "        module_dir = os.path.dirname(module_file) if hasattr(module, '__file__') else 'Unknown'\n",
        "        print(f\"Module directory: {module_dir}\")\n",
        "\n",
        "        # List all attributes and their types\n",
        "        print(\"\\nModule Contents:\")\n",
        "        for attr_name in dir(module):\n",
        "            try:\n",
        "                attr = getattr(module, attr_name)\n",
        "                print(f\"  {attr_name}: {type(attr)}\")\n",
        "            except Exception as attr_err:\n",
        "                print(f\"  {attr_name}: Could not retrieve (Error: {attr_err})\")\n",
        "\n",
        "        # List files in the module directory\n",
        "        if os.path.isdir(module_dir):\n",
        "            print(\"\\nFiles in module directory:\")\n",
        "            try:\n",
        "                for item in os.listdir(module_dir):\n",
        "                    print(f\"  {item}\")\n",
        "            except Exception as list_err:\n",
        "                print(f\"  Could not list directory contents: {list_err}\")\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"Could not import {module_name}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error examining {module_name}: {e}\")\n",
        "\n",
        "# Print Python path and sys.path for debugging\n",
        "print(\"--- Python Path ---\")\n",
        "print(sys.path)\n",
        "\n",
        "# Attempt to import and examine EdgeSimPy\n",
        "print_module_structure('edge_sim_py')\n",
        "\n",
        "# Attempt alternative import methods\n",
        "print(\"\\n--- Alternative Import Attempts ---\")\n",
        "import_attempts = [\n",
        "    'edge_sim_py',\n",
        "    'edge_sim_py.core',\n",
        "    'edge_sim_py.components',\n",
        "    'edge_sim_py.device',\n",
        "    'edge_sim_py.server'\n",
        "]\n",
        "\n",
        "for attempt in import_attempts:\n",
        "    print(f\"\\nTrying to import {attempt}\")\n",
        "    try:\n",
        "        module = importlib.import_module(attempt)\n",
        "        print(f\"Successfully imported {attempt}\")\n",
        "        print(f\"Module file: {getattr(module, '__file__', 'No file attribute')}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"Import failed: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# List installed packages with their paths\n",
        "print(\"\\n--- Installed Packages Paths ---\")\n",
        "for package_name in ['edge_sim_py', 'networkx', 'numpy', 'pandas']:\n",
        "    try:\n",
        "        package = importlib.import_module(package_name)\n",
        "        print(f\"{package_name}: {package.__file__}\")\n",
        "    except ImportError:\n",
        "        print(f\"{package_name}: Not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"{package_name}: Error - {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90E_iTShFiLr",
        "outputId": "a0b6bb07-094e-4c28-a039-0c5b5cbc7d8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Collecting networkx==2.6.2\n",
            "  Downloading networkx-2.6.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading networkx-2.6.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.1 requires networkx>=3.0, but you have networkx 2.6.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.6.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed networkx-2.6.2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting git+https://github.com/EdgeSimPy/EdgeSimPy.git@v1.1.0\n",
            "  Cloning https://github.com/EdgeSimPy/EdgeSimPy.git (to revision v1.1.0) to /tmp/pip-req-build-jwuyr3rx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EdgeSimPy/EdgeSimPy.git /tmp/pip-req-build-jwuyr3rx\n",
            "  Running command git checkout -q 5ea400b39390490b25dabf8be711fe559cb2cbff\n",
            "  Resolved https://github.com/EdgeSimPy/EdgeSimPy.git to commit 5ea400b39390490b25dabf8be711fe559cb2cbff\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Mesa<2.0.0,>=1.0.0 (from edge_sim_py==1.1.0)\n",
            "  Downloading Mesa-1.2.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from edge_sim_py==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: networkx==2.6.2 in /usr/local/lib/python3.11/dist-packages (from edge_sim_py==1.1.0) (2.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (8.1.8)\n",
            "Collecting cookiecutter (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading cookiecutter-2.6.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.2.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (6.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (4.67.1)\n",
            "Collecting binaryornot>=0.4.4 (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.1.5)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (6.0.2)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (8.0.4)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.32.3)\n",
            "Collecting arrow (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (13.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2025.1)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from binaryornot>=0.4.4->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (5.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4.0.0,>=2.7->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify>=4.0.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2024.12.14)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (0.1.2)\n",
            "Downloading Mesa-1.2.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cookiecutter-2.6.0-py3-none-any.whl (39 kB)\n",
            "Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: edge_sim_py\n",
            "  Building wheel for edge_sim_py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for edge_sim_py: filename=edge_sim_py-1.1.0-py3-none-any.whl size=83423 sha256=1ce9585b29e67767e91ae562ecddadc6d683c5f0c124981ecbdb19e159fe939b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5tow3xy8/wheels/61/c9/89/e9391d9c3ba4605a52feea00568aa6ad5471dee92dfe375987\n",
            "Successfully built edge_sim_py\n",
            "Installing collected packages: types-python-dateutil, binaryornot, arrow, cookiecutter, Mesa, edge_sim_py\n",
            "Successfully installed Mesa-1.2.1 arrow-1.3.0 binaryornot-0.4.4 cookiecutter-2.6.0 edge_sim_py-1.1.0 types-python-dateutil-2.9.0.20241206\n",
            "Python 3.11.11\n",
            "edge_sim_py                        1.1.0\n",
            "networkx                           2.6.2\n",
            "--- Python Path ---\n",
            "['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/usr/local/lib/python3.11/dist-packages/setuptools/_vendor', '/root/.ipython']\n",
            "\n",
            "--- Module Structure for edge_sim_py ---\n",
            "Module file path: /usr/local/lib/python3.11/dist-packages/edge_sim_py/__init__.py\n",
            "Module directory: /usr/local/lib/python3.11/dist-packages/edge_sim_py\n",
            "\n",
            "Module Contents:\n",
            "  Application: <class 'type'>\n",
            "  BaseStation: <class 'type'>\n",
            "  CircularDurationAndIntervalAccessPattern: <class 'type'>\n",
            "  ComponentManager: <class 'type'>\n",
            "  ContainerImage: <class 'type'>\n",
            "  ContainerLayer: <class 'type'>\n",
            "  ContainerRegistry: <class 'type'>\n",
            "  ConteratoNetworkPowerModel: <class 'type'>\n",
            "  CubicServerPowerModel: <class 'type'>\n",
            "  EdgeServer: <class 'type'>\n",
            "  LinearServerPowerModel: <class 'type'>\n",
            "  NetworkFlow: <class 'type'>\n",
            "  NetworkLink: <class 'type'>\n",
            "  NetworkSwitch: <class 'type'>\n",
            "  RandomDurationAndIntervalAccessPattern: <class 'type'>\n",
            "  Service: <class 'type'>\n",
            "  Simulator: <class 'type'>\n",
            "  SquareServerPowerModel: <class 'type'>\n",
            "  Topology: <class 'type'>\n",
            "  User: <class 'type'>\n",
            "  __builtins__: <class 'dict'>\n",
            "  __cached__: <class 'str'>\n",
            "  __doc__: <class 'str'>\n",
            "  __file__: <class 'str'>\n",
            "  __loader__: <class '_frozen_importlib_external.SourceFileLoader'>\n",
            "  __name__: <class 'str'>\n",
            "  __package__: <class 'str'>\n",
            "  __path__: <class 'list'>\n",
            "  __spec__: <class '_frozen_importlib.ModuleSpec'>\n",
            "  __version__: <class 'str'>\n",
            "  activation_schedulers: <class 'module'>\n",
            "  application: <class 'module'>\n",
            "  barabasi_albert: <class 'function'>\n",
            "  base_station: <class 'module'>\n",
            "  best_fit_registries: <class 'function'>\n",
            "  best_fit_services: <class 'function'>\n",
            "  builder_helpers: <class 'module'>\n",
            "  circular_duration_and_interval_access_pattern: <class 'module'>\n",
            "  component_manager: <class 'module'>\n",
            "  components: <class 'module'>\n",
            "  container_image: <class 'module'>\n",
            "  container_layer: <class 'module'>\n",
            "  container_registries: <class 'module'>\n",
            "  container_registry: <class 'module'>\n",
            "  conterato_network_power_model: <class 'module'>\n",
            "  create_container_registries: <class 'function'>\n",
            "  cubic_server_power_model: <class 'module'>\n",
            "  dataset_generator: <class 'module'>\n",
            "  e5430: <class 'function'>\n",
            "  e5507: <class 'function'>\n",
            "  e5645: <class 'function'>\n",
            "  edge_server: <class 'module'>\n",
            "  edge_servers: <class 'module'>\n",
            "  equal_share: <class 'function'>\n",
            "  flow_scheduling: <class 'module'>\n",
            "  hexagonal_grid: <class 'function'>\n",
            "  jetson_nano: <class 'function'>\n",
            "  jetson_tx2: <class 'function'>\n",
            "  linear_server_power_model: <class 'module'>\n",
            "  map: <class 'module'>\n",
            "  max_min_fairness: <class 'function'>\n",
            "  mobility_models: <class 'module'>\n",
            "  network: <class 'module'>\n",
            "  network_flow: <class 'module'>\n",
            "  network_link: <class 'module'>\n",
            "  network_switch: <class 'module'>\n",
            "  network_switches: <class 'module'>\n",
            "  network_topologies: <class 'module'>\n",
            "  partially_connected_hexagonal_mesh: <class 'function'>\n",
            "  pathway: <class 'function'>\n",
            "  placement: <class 'module'>\n",
            "  power_models: <class 'module'>\n",
            "  provision_container_registry: <class 'function'>\n",
            "  quadratic_grid: <class 'function'>\n",
            "  random_duration_and_interval_access_pattern: <class 'module'>\n",
            "  random_fit_registries: <class 'function'>\n",
            "  random_fit_services: <class 'function'>\n",
            "  random_mobility: <class 'function'>\n",
            "  raspberry_pi4: <class 'function'>\n",
            "  sample_switch: <class 'function'>\n",
            "  servers: <class 'module'>\n",
            "  service: <class 'module'>\n",
            "  services: <class 'module'>\n",
            "  simulator: <class 'module'>\n",
            "  square_server_power_model: <class 'module'>\n",
            "  topology: <class 'module'>\n",
            "  user: <class 'module'>\n",
            "  user_access_patterns: <class 'module'>\n",
            "  worst_fit_registries: <class 'function'>\n",
            "  worst_fit_services: <class 'function'>\n",
            "\n",
            "Files in module directory:\n",
            "  dataset_generator\n",
            "  activation_schedulers\n",
            "  components\n",
            "  __init__.py\n",
            "  __pycache__\n",
            "  component_manager.py\n",
            "  simulator.py\n",
            "\n",
            "--- Alternative Import Attempts ---\n",
            "\n",
            "Trying to import edge_sim_py\n",
            "Successfully imported edge_sim_py\n",
            "Module file: /usr/local/lib/python3.11/dist-packages/edge_sim_py/__init__.py\n",
            "\n",
            "Trying to import edge_sim_py.core\n",
            "Import failed: No module named 'edge_sim_py.core'\n",
            "\n",
            "Trying to import edge_sim_py.components\n",
            "Successfully imported edge_sim_py.components\n",
            "Module file: /usr/local/lib/python3.11/dist-packages/edge_sim_py/components/__init__.py\n",
            "\n",
            "Trying to import edge_sim_py.device\n",
            "Import failed: No module named 'edge_sim_py.device'\n",
            "\n",
            "Trying to import edge_sim_py.server\n",
            "Import failed: No module named 'edge_sim_py.server'\n",
            "\n",
            "--- Installed Packages Paths ---\n",
            "edge_sim_py: /usr/local/lib/python3.11/dist-packages/edge_sim_py/__init__.py\n",
            "networkx: /usr/local/lib/python3.11/dist-packages/networkx/__init__.py\n",
            "numpy: /usr/local/lib/python3.11/dist-packages/numpy/__init__.py\n",
            "pandas: /usr/local/lib/python3.11/dist-packages/pandas/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OekA2N9EdDe"
      },
      "source": [
        "## Implementing the Placement Algorithm\n",
        "\n",
        "In this example, we are going to create a simple placement algorithm that works according to the well-known First-Fit heuristic. In a nutshell, our algorithm will provision each service to the first edge server with available resources to host them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YMjHk8QGEdDf"
      },
      "outputs": [],
      "source": [
        "def my_algorithm(parameters):\n",
        "    # We can always call the 'all()' method to get a list with all created instances of a given class\n",
        "    for service in Service.all():\n",
        "        # We don't want to migrate services are are already being migrated\n",
        "        if service.server == None and not service.being_provisioned:\n",
        "\n",
        "            # Let's iterate over the list of edge servers to find a suitable host for our service\n",
        "            for edge_server in EdgeServer.all():\n",
        "\n",
        "                # We must check if the edge server has enough resources to host the service\n",
        "                if edge_server.has_capacity_to_host(service=service):\n",
        "\n",
        "                    # Start provisioning the service in the edge server\n",
        "                    service.provision(target_server=edge_server)\n",
        "\n",
        "                    # After start migrating the service we can move on to the next service\n",
        "                    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-cM8aGFEdDf"
      },
      "source": [
        "## Running the Simulation\n",
        "\n",
        "As we're creating a placement algorithm, we must instruct EdgeSimPy that it needs to continue the simulation until all services are provisioned within the infrastructure.\n",
        "\n",
        "To do so, let's create a simple function that will be used as the simulation's stopping criterion. EdgeSimPy will run that function at the end of each time step, halting the simulation as soon as it returns `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1Tl2gzLhEdDf"
      },
      "outputs": [],
      "source": [
        "def stopping_criterion(model: object):\n",
        "    # Defining a variable that will help us to count the number of services successfully provisioned within the infrastructure\n",
        "    provisioned_services = 0\n",
        "\n",
        "    # Iterating over the list of services to count the number of services provisioned within the infrastructure\n",
        "    for service in Service.all():\n",
        "\n",
        "        # Initially, services are not hosted by any server (i.e., their \"server\" attribute is None).\n",
        "        # Once that value changes, we know that it has been successfully provisioned inside an edge server.\n",
        "        if service.server != None:\n",
        "            provisioned_services += 1\n",
        "\n",
        "    # As EdgeSimPy will halt the simulation whenever this function returns True, its output will be a boolean expression\n",
        "    # that checks if the number of provisioned services equals to the number of services spawned in our simulation\n",
        "    return provisioned_services == Service.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab Setup for FCFS Task Processing\n",
        "\n"
      ],
      "metadata": {
        "id": "eAhUsANCM7I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Setup for FCFS Task Processing\n",
        "\n",
        "# Install required libraries\n",
        "!pip install numpy\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List files in the task sets directory\n",
        "import os\n",
        "task_sets_dir = '/content/drive/My Drive/FCFS_Task_Sets/'\n",
        "print(\"Available task set files:\")\n",
        "for filename in os.listdir(task_sets_dir):\n",
        "    print(filename)\n",
        "\n",
        "# Note: After running this, copy the full path of the desired JSON file\n",
        "# and use it in the main FCFS scheduler script"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58DabUIvM_9q",
        "outputId": "71b0309a-7c4b-46b9-8afe-48d4fbc8ad69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Mounted at /content/drive\n",
            "Available task set files:\n",
            "fcfs_task_set_20250201_201915.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FCFS Algorithm Logic\n"
      ],
      "metadata": {
        "id": "5eHWaH4xIzc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# Configure logging to print to console\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout)  # Explicitly add console output\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Print function to ensure output\n",
        "def print_to_console(*args, **kwargs):\n",
        "    \"\"\"\n",
        "    Wrapper function to ensure printing\n",
        "    \"\"\"\n",
        "    print(*args, **kwargs)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 data_size: float,     # in MB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = self.details.get('task_name', f'Task_{task_id}')\n",
        "        self.size = self.details.get('size', 'unspecified')\n",
        "        self.type = self.details.get('type', 'unknown')\n",
        "        self.task_class = self.details.get('task_class', 'generic')\n",
        "        self.cpu_intensity = self.details.get('cpu_intensity', 'medium')\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with enhanced tracking and visualization\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int):    # in MB/s\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue\n",
        "        \"\"\"\n",
        "        task.queue_position = len(self.task_queue)\n",
        "        self.task_queue.append(task)\n",
        "\n",
        "    def process_queue(self, current_time: float):\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking\n",
        "        \"\"\"\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            processing_result = task.process(self.cpu_rating)\n",
        "\n",
        "            # Detailed task processing output\n",
        "            self._log_task_processing(task, processing_result)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "\n",
        "        # If resource has available capacity, move tasks from queue to current tasks\n",
        "        while self.task_queue and len(self.current_tasks) < 5:  # Limit concurrent tasks\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "\n",
        "        return len(self.current_tasks)\n",
        "\n",
        "    def _log_task_processing(self, task: Task, processing_result: Dict):\n",
        "        \"\"\"\n",
        "        Log detailed task processing information\n",
        "        \"\"\"\n",
        "        print_to_console(\n",
        "            f\"Resource {self.id} ({self.type}) - \"\n",
        "            f\"Task {task.id} ({task.task_name}): \"\n",
        "            f\"Processed {processing_result['processed']:.2f} MI, \"\n",
        "            f\"Remaining {processing_result['remaining']:.2f} MI, \"\n",
        "            f\"Completion: {processing_result['completion_percentage']:.2f}%\"\n",
        "        )\n",
        "\n",
        "class AdvancedFCFSScheduler:\n",
        "    \"\"\"\n",
        "    Advanced First-Come-First-Serve Scheduler with Real-Time Visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_time = 0\n",
        "\n",
        "        # Metrics tracking with enhanced details\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'completed_tasks': 0,\n",
        "            'queued_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'resource_utilization': {},\n",
        "            'average_wait_time': 0,\n",
        "            'max_wait_time': 0\n",
        "        }\n",
        "\n",
        "    def load_tasks_from_json(self, json_path: str) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Load tasks from JSON with comprehensive parsing\n",
        "        \"\"\"\n",
        "        print_to_console(f\"Attempting to load tasks from: {json_path}\")\n",
        "\n",
        "        with open(json_path, 'r') as f:\n",
        "            task_data = json.load(f)\n",
        "\n",
        "        tasks_list = task_data.get('tasks', [])\n",
        "\n",
        "        tasks = []\n",
        "        for task_dict in tasks_list:\n",
        "            task = Task(\n",
        "                task_id=task_dict.get('id', len(tasks) + 1),\n",
        "                data_size=task_dict.get('data_size', 10),  # Default 10 MB\n",
        "                cpu_required=task_dict.get('instructions', 50000),  # Default 50,000 MI\n",
        "                task_details=task_dict\n",
        "            )\n",
        "            task.arrival_time = self.current_time\n",
        "            tasks.append(task)\n",
        "\n",
        "        print_to_console(f\"Loaded {len(tasks)} tasks from JSON\")\n",
        "        return tasks\n",
        "\n",
        "    def distribute_tasks(self):\n",
        "        \"\"\"\n",
        "        Distribute tasks across resources with advanced visualization\n",
        "        \"\"\"\n",
        "        tasks = self.load_tasks_from_json(\n",
        "            '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\n",
        "        )\n",
        "        self.metrics['total_tasks'] = len(tasks)\n",
        "\n",
        "        # Track task distribution\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Round-robin task distribution with visualization\n",
        "        resource_index = 0\n",
        "        for task in tasks:\n",
        "            # Select resource\n",
        "            resource = self.resources[resource_index]\n",
        "\n",
        "            # Enqueue task\n",
        "            resource.enqueue_task(task)\n",
        "            task_distribution[resource.type] += 1\n",
        "\n",
        "            # Cycle through resources\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        # Update metrics\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "        self.metrics['queued_tasks'] = sum(len(resource.task_queue) for resource in self.resources)\n",
        "\n",
        "        # Print initial distribution\n",
        "        print_to_console(\"\\n--- Initial Task Distribution ---\")\n",
        "        for resource_type, count in task_distribution.items():\n",
        "            print_to_console(f\"{resource_type}: {count} tasks\")\n",
        "\n",
        "        print_to_console(\"\\n--- Resource Queue Lengths ---\")\n",
        "        for i, resource in enumerate(self.resources, 1):\n",
        "            print_to_console(f\"Resource {i} ({resource.type}) Queue Length: {len(resource.task_queue)} tasks\")\n",
        "\n",
        "    def run_simulation(self, max_iterations: int = 1000):\n",
        "        \"\"\"\n",
        "        Run scheduling simulation with real-time visualization\n",
        "        \"\"\"\n",
        "        # Distribute tasks initially\n",
        "        self.distribute_tasks()\n",
        "\n",
        "        # Simulation loop with enhanced visualization\n",
        "        start_time = time.time()\n",
        "        for iteration in range(max_iterations):\n",
        "            print_to_console(f\"\\n--- Iteration {iteration} ---\")\n",
        "\n",
        "            # Process queues for all resources\n",
        "            completed_in_iteration = 0\n",
        "            resource_utilization = {}\n",
        "\n",
        "            for resource in self.resources:\n",
        "                # Track resource utilization\n",
        "                initial_completed = len(resource.completed_tasks)\n",
        "                resource.process_queue(self.current_time)\n",
        "                completed_this_resource = len(resource.completed_tasks) - initial_completed\n",
        "                completed_in_iteration += completed_this_resource\n",
        "\n",
        "                # Calculate resource utilization\n",
        "                resource_utilization[resource.type] = {\n",
        "                    'completed_tasks': completed_this_resource,\n",
        "                    'current_tasks': len(resource.current_tasks),\n",
        "                    'queue_length': len(resource.task_queue)\n",
        "                }\n",
        "\n",
        "            # Update metrics\n",
        "            self.metrics['completed_tasks'] = sum(\n",
        "                len(resource.completed_tasks) for resource in self.resources\n",
        "            )\n",
        "            self.metrics['resource_utilization'] = resource_utilization\n",
        "\n",
        "            # Print real-time resource utilization\n",
        "            print_to_console(\"\\n--- Resource Utilization ---\")\n",
        "            for resource_type, stats in resource_utilization.items():\n",
        "                print_to_console(\n",
        "                    f\"{resource_type}: \"\n",
        "                    f\"Completed: {stats['completed_tasks']}, \"\n",
        "                    f\"Current Tasks: {stats['current_tasks']}, \"\n",
        "                    f\"Queue Length: {stats['queue_length']}\"\n",
        "                )\n",
        "\n",
        "            # Check if all tasks are processed\n",
        "            if self.metrics['completed_tasks'] == self.metrics['total_tasks']:\n",
        "                print_to_console(\"\\n--- All Tasks Processed! ---\")\n",
        "                break\n",
        "\n",
        "            # Increment time\n",
        "            self.current_time += 1\n",
        "\n",
        "            # Optional: Add a small delay to simulate real-time processing\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        # Calculate total processing time\n",
        "        total_processing_time = time.time() - start_time\n",
        "        self.metrics['total_processing_time'] = total_processing_time\n",
        "\n",
        "        # Calculate wait time metrics\n",
        "        self.calculate_wait_time_metrics()\n",
        "\n",
        "        return self.metrics\n",
        "\n",
        "    def calculate_wait_time_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculate comprehensive wait time metrics\n",
        "        \"\"\"\n",
        "        all_completed_tasks = []\n",
        "        for resource in self.resources:\n",
        "            all_completed_tasks.extend(resource.completed_tasks)\n",
        "\n",
        "        if all_completed_tasks:\n",
        "            wait_times = [task.wait_time for task in all_completed_tasks]\n",
        "            self.metrics['average_wait_time'] = sum(wait_times) / len(wait_times)\n",
        "            self.metrics['max_wait_time'] = max(wait_times)\n",
        "\n",
        "def create_original_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    # Explicitly set print to console\n",
        "    print = print_to_console\n",
        "\n",
        "    # Create resources matching original configuration\n",
        "    resources = create_original_resources()\n",
        "\n",
        "    # Print initial resource details\n",
        "    print(\"\\n--- Resource Configurations ---\")\n",
        "    for resource in resources:\n",
        "        print(f\"Resource {resource.id} ({resource.type}):\")\n",
        "        print(f\"  CPU Rating: {resource.cpu_rating} MI/s\")\n",
        "        print(f\"  Memory: {resource.memory} GB\")\n",
        "        print(f\"  Bandwidth: {resource.bandwidth} MB/s\")\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = AdvancedFCFSScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    metrics = scheduler.run_simulation()\n",
        "\n",
        "    # Print final detailed metrics\n",
        "    print(\"\\n--- Final Scheduling Metrics ---\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "\n",
        "    # Detailed resource reporting\n",
        "    print(\"\\n--- Final Resource Status ---\")\n",
        "    for resource in scheduler.resources:\n",
        "        print(f\"\\nResource {resource.id} ({resource.type}):\")\n",
        "        print(f\"Completed Tasks: {len(resource.completed_tasks)}\")\n",
        "        print(f\"Remaining Queue: {len(resource.task_queue)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "collapsed": true,
        "id": "Mt0lGxw0I4Y0",
        "outputId": "7ebd6944-e322-4ae6-b9be-614d43dd944e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resource Configurations ---\n",
            "Resource 1 (Edge_Raspberry_Pi):\n",
            "  CPU Rating: 80000 MI/s\n",
            "  Memory: 1 GB\n",
            "  Bandwidth: 5 MB/s\n",
            "Resource 2 (Edge_Smartphone):\n",
            "  CPU Rating: 400000 MI/s\n",
            "  Memory: 4 GB\n",
            "  Bandwidth: 20 MB/s\n",
            "Resource 3 (Cloud_Host):\n",
            "  CPU Rating: 1000000 MI/s\n",
            "  Memory: 32 GB\n",
            "  Bandwidth: 80 MB/s\n",
            "Attempting to load tasks from: /content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;31m# Run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# Print final detailed metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(self, max_iterations)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Distribute tasks initially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Simulation loop with enhanced visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mdistribute_tasks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mDistribute\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0macross\u001b[0m \u001b[0mresources\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0madvanced\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         tasks = self.load_tasks_from_json(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;34m'/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mload_tasks_from_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mprint_to_console\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to load tasks from: {json_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mtask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Rich in FCFS"
      ],
      "metadata": {
        "id": "o9zVR42wVLWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.layout import Layout\n",
        "from rich.live import Live\n",
        "from rich.text import Text\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 task_type: str,\n",
        "                 data_size: float,     # in GB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.type = task_type\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = f\"{task_type}_Task_{task_id}\"\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with comprehensive tracking and utilization metrics\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int,     # in MB/s\n",
        "                 num_cpus: int = 1):  # Number of CPUs, defaulting to 1\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.total_memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # CPU configuration\n",
        "        self.num_cpus = num_cpus\n",
        "        self.available_cpus = num_cpus\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Utilization tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.current_memory_usage = 0\n",
        "\n",
        "        # Additional tracking\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "    def can_process_task(self, task: Task) -> bool:\n",
        "        \"\"\"\n",
        "        Check if the resource can process the given task\n",
        "        \"\"\"\n",
        "        # Check if CPUs are available\n",
        "        if self.available_cpus <= 0:\n",
        "            return False\n",
        "\n",
        "        # Cloud host can process all task types\n",
        "        if self.type == \"Cloud_Host\":\n",
        "            return True\n",
        "\n",
        "        # Edge nodes (Raspberry Pi and Smartphone) can only process RT2 tasks\n",
        "        if self.type in [\"Edge_Raspberry_Pi\", \"Edge_Smartphone\"]:\n",
        "            # Explicitly fail RT1 and RT3 tasks on edge resources\n",
        "            if task.type in [\"RT1\", \"RT3\"]:\n",
        "                logger.warning(f\"Task {task.id} of type {task.type} FAILED on {self.type}\")\n",
        "                return False\n",
        "\n",
        "            # Additional memory check for RT2 tasks\n",
        "            if task.data_size > self.total_memory:\n",
        "                logger.warning(f\"Task {task.id} requires {task.data_size} GB, exceeding {self.type}'s memory of {self.total_memory} GB\")\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue if it can be processed\n",
        "        \"\"\"\n",
        "        if self.can_process_task(task):\n",
        "            task.queue_position = len(self.task_queue)\n",
        "            task.arrival_time = time.time()\n",
        "            self.task_queue.append(task)\n",
        "        else:\n",
        "            # Mark task as failed\n",
        "            task.status = 'failed'\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking and utilization update\n",
        "        \"\"\"\n",
        "        # Reset current usage and task tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "        # Reset available CPUs\n",
        "        self.available_cpus = self.num_cpus\n",
        "\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            # Skip if no CPUs available\n",
        "            if self.available_cpus <= 0:\n",
        "                break\n",
        "\n",
        "            # Determine how much CPU can be used for this task\n",
        "            task_cpu = min(self.cpu_rating, task.remaining_cpu)\n",
        "\n",
        "            processing_result = task.process(task_cpu)\n",
        "\n",
        "            # Update CPU usage\n",
        "            processed_amount = processing_result['processed']\n",
        "            self.current_cpu_usage += processed_amount\n",
        "\n",
        "            # Track detailed task information\n",
        "            task_info = {\n",
        "                'id': task.id,\n",
        "                'name': task.task_name,\n",
        "                'type': task.type,\n",
        "                'processed': processed_amount,\n",
        "                'total_required': task.total_cpu_required,\n",
        "                'completion_percentage': processing_result['completion_percentage']\n",
        "            }\n",
        "            self.detailed_task_tracking.append(task_info)\n",
        "\n",
        "            # Calculate task CPU demand\n",
        "            task_demand = processed_amount / self.cpu_rating\n",
        "            self.task_cpu_demands.append(task_demand)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "                # Free up a CPU\n",
        "                self.available_cpus += 1\n",
        "\n",
        "        # Move tasks from queue to current tasks if CPUs are available\n",
        "        while self.task_queue and self.available_cpus > 0:\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "            # Use up a CPU\n",
        "            self.available_cpus -= 1\n",
        "\n",
        "        # Calculate CPU utilization\n",
        "        if self.task_cpu_demands:\n",
        "            cpu_utilization = min(sum(self.task_cpu_demands) * 100, 100)\n",
        "        else:\n",
        "            cpu_utilization = 0\n",
        "\n",
        "        # Estimate memory usage\n",
        "        self.current_memory_usage = len(self.current_tasks) * (self.total_memory / 10)\n",
        "        memory_utilization = min((self.current_memory_usage / self.total_memory) * 100, 100)\n",
        "\n",
        "        # Return detailed resource state with utilization\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'cpu_utilization': cpu_utilization,\n",
        "            'memory_utilization': memory_utilization,\n",
        "            'raw_cpu_usage': self.current_cpu_usage,\n",
        "            'task_demands': self.task_cpu_demands,\n",
        "            'detailed_tasks': self.detailed_task_tracking,\n",
        "            'available_cpus': self.available_cpus\n",
        "        }\n",
        "\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources with 10 Smartphones, 5 Raspberry Pis, and 5 Cloud Hosts\n",
        "    \"\"\"\n",
        "    resources = []\n",
        "\n",
        "    # Create 10 Smartphone Edge Nodes\n",
        "    for i in range(1, 11):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i,\n",
        "                resource_type=f\"Edge_{i}\",\n",
        "                cpu_rating=400000,   # 400,000 MI/s\n",
        "                memory=4,            # 4 GB\n",
        "                bandwidth=20         # 20 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Raspberry Pi Edge Nodes\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+10,  # IDs 11-15\n",
        "                resource_type=f\"Raspberry_{i}\",\n",
        "                cpu_rating=80000,    # 80,000 MI/s\n",
        "                memory=1,            # 1 GB\n",
        "                bandwidth=5          # 5 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Cloud Hosts\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+15,  # IDs 16-20\n",
        "                resource_type=f\"Cloud_{i}\",\n",
        "                cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "                memory=32,           # 32 GB\n",
        "                bandwidth=80         # 80 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return resources\n",
        "\n",
        "class ResourceFocusedScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with resource-focused real-time visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.current_time = 0\n",
        "        self.console = Console()\n",
        "\n",
        "        # Poisson process parameters\n",
        "        self.arrival_rate = 0.8  # λ = 0.8 tasks per second\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'completed_tasks': 0,\n",
        "            'failed_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'makespan': 0,\n",
        "            'throughput': 0\n",
        "        }\n",
        "\n",
        "    def generate_tasks(self, simulation_time: float = 100) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Generate tasks using Poisson process\n",
        "        \"\"\"\n",
        "        # Task types and their characteristics based on the paper\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"data_size\": 5.0, \"cpu_required\": 2_000_000},   # CPU-intensive, memory-intensive\n",
        "            {\"type\": \"RT2\", \"data_size\": 0.2, \"cpu_required\": 4_000_000},   # CPU-intensive, memory-light\n",
        "            {\"type\": \"RT3\", \"data_size\": 5.0, \"cpu_required\": 200_000},     # CPU-light, memory-intensive\n",
        "            {\"type\": \"RT4\", \"data_size\": 0.5, \"cpu_required\": 500_000}      # CPU-light, memory-light\n",
        "        ]\n",
        "\n",
        "        # Generate task arrival times using Poisson process\n",
        "        num_tasks = np.random.poisson(self.arrival_rate * simulation_time)\n",
        "\n",
        "        tasks = []\n",
        "        for i in range(num_tasks):\n",
        "            # Randomly select task type\n",
        "            task_type_data = np.random.choice(task_types)\n",
        "\n",
        "            task = Task(\n",
        "                task_id=i+1,\n",
        "                task_type=task_type_data['type'],\n",
        "                data_size=task_type_data['data_size'],\n",
        "                cpu_required=task_type_data['cpu_required']\n",
        "            )\n",
        "\n",
        "            # Set arrival time\n",
        "            task.arrival_time = np.random.uniform(0, simulation_time)\n",
        "\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Sort tasks by arrival time\n",
        "        return sorted(tasks, key=lambda x: x.arrival_time)\n",
        "    def _create_resource_panel(self, resource: Resource, status: Dict) -> Panel:\n",
        "        \"\"\"\n",
        "        Create a detailed panel for a specific resource with comprehensive task information\n",
        "        \"\"\"\n",
        "        # Create table for resource details\n",
        "        table = Table(show_header=False, show_lines=True)\n",
        "\n",
        "        # Resource basic information\n",
        "        table.add_row(\"[bold]Resource Details[/bold]\")\n",
        "        table.add_row(f\"[cyan]Type:[/cyan] {resource.type}\")\n",
        "        table.add_row(f\"[green]CPU Rating:[/green] {resource.cpu_rating} MI/s\")\n",
        "        table.add_row(f\"[blue]Memory:[/blue] {resource.total_memory} GB\")\n",
        "        table.add_row(f\"[yellow]Bandwidth:[/yellow] {resource.bandwidth} MB/s\")\n",
        "\n",
        "        # Utilization information\n",
        "        table.add_row(\"\\n[bold]Utilization Metrics[/bold]\")\n",
        "        table.add_row(\n",
        "            f\"[green]CPU Usage:[/green] {status['cpu_utilization']:.2f}% \"\n",
        "            f\"({status['raw_cpu_usage']:.2f}/{resource.cpu_rating} MI/s)\"\n",
        "        )\n",
        "\n",
        "        # Task Queue Information\n",
        "        table.add_row(\"\\n[bold]Task Queue[/bold]\")\n",
        "        table.add_row(f\"[yellow]Queued Tasks:[/yellow] {status['queue_length']}\")\n",
        "\n",
        "        # Current Tasks\n",
        "        table.add_row(\"\\n[bold]Current Tasks[/bold]\")\n",
        "        if status['detailed_tasks']:\n",
        "            for task in status['detailed_tasks']:\n",
        "                table.add_row(\n",
        "                    f\"[blue]Task {task['id']} ({task['type']}):[/blue] \"\n",
        "                    f\"Processed {task['processed']:.2f}/{task['total_required']} MI \"\n",
        "                    f\"({task['completion_percentage']:.2f}%)\"\n",
        "                )\n",
        "        else:\n",
        "            table.add_row(\"[dim]No tasks currently processing[/dim]\")\n",
        "\n",
        "        # Memory Usage\n",
        "        table.add_row(\n",
        "            f\"[blue]Memory Usage:[/blue] {status['memory_utilization']:.2f}% \"\n",
        "            f\"({resource.current_memory_usage:.2f}/{resource.total_memory} GB)\"\n",
        "        )\n",
        "\n",
        "        # Task Processing Status\n",
        "        table.add_row(\"\\n[bold]Task Processing Summary[/bold]\")\n",
        "        table.add_row(f\"[green]Completed Tasks:[/green] {status['completed_tasks']}\")\n",
        "        table.add_row(f\"[yellow]Current Tasks:[/yellow] {status['current_tasks']}\")\n",
        "\n",
        "        # Detailed task queue information\n",
        "        table.add_row(\"\\n[bold]Detailed Task Queue[/bold]\")\n",
        "        if resource.task_queue:\n",
        "            for idx, task in enumerate(resource.task_queue[:5], 1):\n",
        "                table.add_row(\n",
        "                    f\"[yellow]Queued Task {idx}:[/yellow] \"\n",
        "                    f\"ID: {task.id}, Type: {task.type}, \"\n",
        "                    f\"CPU Required: {task.total_cpu_required} MI\"\n",
        "                )\n",
        "            if len(resource.task_queue) > 5:\n",
        "                table.add_row(f\"[dim]... and {len(resource.task_queue) - 5} more tasks[/dim]\")\n",
        "        else:\n",
        "            table.add_row(\"[dim]No tasks in queue[/dim]\")\n",
        "\n",
        "        # Create panel with resource-specific styling\n",
        "        return Panel(\n",
        "            table,\n",
        "            title=f\"Resource {resource.id}: {resource.type}\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "\n",
        "    def distribute_tasks(self, total_tasks: int = 1500) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Generate and distribute a fixed number of tasks\n",
        "        \"\"\"\n",
        "        # Task types and their characteristics based on the paper\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"data_size\": 5.0, \"cpu_required\": 2_000_000},   # CPU-intensive, memory-intensive\n",
        "            {\"type\": \"RT2\", \"data_size\": 0.2, \"cpu_required\": 4_000_000},   # CPU-intensive, memory-light\n",
        "            {\"type\": \"RT3\", \"data_size\": 5.0, \"cpu_required\": 200_000},     # CPU-light, memory-intensive\n",
        "            {\"type\": \"RT4\", \"data_size\": 0.5, \"cpu_required\": 500_000}      # CPU-light, memory-light\n",
        "        ]\n",
        "\n",
        "        # Generate tasks\n",
        "        tasks = []\n",
        "        for i in range(total_tasks):\n",
        "            # Randomly select task type\n",
        "            task_type_data = np.random.choice(task_types)\n",
        "\n",
        "            task = Task(\n",
        "                task_id=i+1,\n",
        "                task_type=task_type_data['type'],\n",
        "                data_size=task_type_data['data_size'],\n",
        "                cpu_required=task_type_data['cpu_required']\n",
        "            )\n",
        "\n",
        "            # Set arrival time with uniform distribution\n",
        "            task.arrival_time = np.random.uniform(0, 100)  # Distribute over 100 seconds\n",
        "\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Sort tasks by arrival time\n",
        "        tasks.sort(key=lambda x: x.arrival_time)\n",
        "\n",
        "        # Update metrics\n",
        "        self.metrics['total_tasks'] = total_tasks\n",
        "\n",
        "        # Explicitly select edge, raspberry, and cloud resources\n",
        "        edge_resources = [r for r in self.resources if r.type.startswith(\"Edge_\")]\n",
        "        raspberry_resources = [r for r in self.resources if r.type.startswith(\"Raspberry_\")]\n",
        "        cloud_resources = [r for r in self.resources if r.type.startswith(\"Cloud_\")]\n",
        "\n",
        "        # Define resource order as specified in the paper\n",
        "        # Order: Smartphone, Raspberry Pi, Cloud\n",
        "        resource_order = edge_resources + raspberry_resources + cloud_resources\n",
        "\n",
        "        # Track task distribution and failures\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "        failed_tasks_by_resource = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Circular resource selection\n",
        "        resource_index = 0\n",
        "        num_resources = len(resource_order)\n",
        "\n",
        "        for task in tasks:\n",
        "            # Select resource in the specified order\n",
        "            resource = resource_order[resource_index]\n",
        "\n",
        "            # Attempt to enqueue task\n",
        "            if resource.can_process_task(task):\n",
        "                resource.enqueue_task(task)\n",
        "                task_distribution[resource.type] += 1\n",
        "            else:\n",
        "                # Increment failed tasks for the specific resource type\n",
        "                failed_tasks_by_resource[resource.type] += 1\n",
        "                self.metrics['failed_tasks'] += 1\n",
        "\n",
        "            # Move to next resource in circular manner\n",
        "            resource_index = (resource_index + 1) % num_resources\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        # Print distribution table\n",
        "        distribution_table = Table(title=\"Task Distribution\")\n",
        "        distribution_table.add_column(\"Resource\", style=\"cyan\")\n",
        "        distribution_table.add_column(\"Tasks\", style=\"magenta\")\n",
        "        distribution_table.add_column(\"Failed Tasks\", style=\"red\")\n",
        "\n",
        "        for resource_type in task_distribution:\n",
        "            distribution_table.add_row(\n",
        "                resource_type,\n",
        "                str(task_distribution[resource_type]),\n",
        "                str(failed_tasks_by_resource[resource_type])\n",
        "            )\n",
        "\n",
        "        self.console.print(distribution_table)\n",
        "\n",
        "        return tasks\n",
        "    def run_simulation(self, total_tasks: int = 1500, max_iterations: int = 10000):\n",
        "        \"\"\"\n",
        "        Run simulation with a fixed number of tasks\n",
        "        \"\"\"\n",
        "        # Record start time\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        # Distribute tasks\n",
        "        tasks = self.distribute_tasks(total_tasks)\n",
        "\n",
        "        # Prepare layout for live visualization\n",
        "        layout = Layout()\n",
        "\n",
        "        # Calculate layout grid\n",
        "        num_resources = len(self.resources)\n",
        "        grid_cols = 5  # 5 columns\n",
        "        grid_rows = (num_resources + grid_cols - 1) // grid_cols\n",
        "\n",
        "        # Dynamically create layout\n",
        "        layout_splits = []\n",
        "        for row in range(grid_rows):\n",
        "            row_layouts = []\n",
        "            for col in range(grid_cols):\n",
        "                resource_idx = row * grid_cols + col\n",
        "                if resource_idx < num_resources:\n",
        "                    row_layouts.append(Layout(name=f\"resource_{resource_idx}\"))\n",
        "\n",
        "            if row_layouts:\n",
        "                layout_splits.append(Layout().split_row(*row_layouts))\n",
        "\n",
        "        layout.split_column(*layout_splits)\n",
        "\n",
        "        # Live visualization\n",
        "        with Live(layout, console=self.console, refresh_per_second=10) as live:\n",
        "            for iteration in range(max_iterations):\n",
        "                # Calculate current simulation time\n",
        "                current_simulation_time = time.time() - self.start_time\n",
        "\n",
        "                # Process tasks on each resource\n",
        "                for idx, resource in enumerate(self.resources):\n",
        "                    # Process resource queue\n",
        "                    resource_status = resource.process_queue(current_simulation_time)\n",
        "\n",
        "                    # Update layout with resource-specific panel\n",
        "                    layout[f\"resource_{idx}\"].update(\n",
        "                        self._create_resource_panel(resource, resource_status)\n",
        "                    )\n",
        "\n",
        "                # Update live display\n",
        "                live.update(layout)\n",
        "\n",
        "                # Track completed and failed tasks across all resources\n",
        "                total_processed_tasks = sum(\n",
        "                    len(resource.completed_tasks) for resource in self.resources\n",
        "                ) + self.metrics['failed_tasks']\n",
        "\n",
        "                # Check if all tasks are processed (completed or failed)\n",
        "                if total_processed_tasks >= total_tasks:\n",
        "                    logger.info(f\"Simulation completed in {iteration} iterations\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "        # Calculate final metrics\n",
        "        completed_tasks = sum(len(resource.completed_tasks) for resource in self.resources)\n",
        "        self.metrics['completed_tasks'] = completed_tasks\n",
        "        self.metrics['makespan'] = time.time() - self.start_time\n",
        "\n",
        "        return self.metrics\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources with 10 Smartphones, 5 Raspberry Pis, and 5 Cloud Hosts\n",
        "    \"\"\"\n",
        "    resources = []\n",
        "\n",
        "    # Create 10 Smartphone Edge Nodes\n",
        "    for i in range(1, 11):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i,\n",
        "                resource_type=f\"Edge_{i}\",\n",
        "                cpu_rating=400000,   # 400,000 MI/s\n",
        "                memory=4,            # 4 GB\n",
        "                bandwidth=20         # 20 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Raspberry Pi Edge Nodes\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+10,  # IDs 11-15\n",
        "                resource_type=f\"Raspberry_{i}\",\n",
        "                cpu_rating=80000,    # 80,000 MI/s\n",
        "                memory=1,            # 1 GB\n",
        "                bandwidth=5          # 5 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Cloud Hosts\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+15,  # IDs 16-20\n",
        "                resource_type=f\"Cloud_{i}\",\n",
        "                cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "                memory=32,           # 32 GB\n",
        "                bandwidth=80         # 80 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return resources\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main simulation entry point\n",
        "    \"\"\"\n",
        "    # Create resources\n",
        "    resources = create_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = ResourceFocusedScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    try:\n",
        "        # Run simulation for 1500 tasks\n",
        "        metrics = scheduler.run_simulation(total_tasks=1500)\n",
        "\n",
        "        # Print comprehensive metrics\n",
        "        print(\"\\n--- Simulation Metrics ---\")\n",
        "        print(f\"Total Tasks Generated: {metrics['total_tasks']}\")\n",
        "        print(f\"Completed Tasks: {metrics['completed_tasks']}\")\n",
        "        print(f\"Failed Tasks: {metrics['failed_tasks']}\")\n",
        "\n",
        "        # Print detailed task distribution\n",
        "        print(\"\\nTask Distribution:\")\n",
        "        for resource_type, count in metrics['task_distribution'].items():\n",
        "            print(f\"{resource_type}: {count}\")\n",
        "\n",
        "        # Print resource-specific details\n",
        "        print(\"\\nResource Performance Details:\")\n",
        "        for resource in resources:\n",
        "            # Get resource status\n",
        "            status = resource.process_queue(metrics['makespan'])\n",
        "\n",
        "            print(f\"\\nResource {resource.id} - {resource.type}:\")\n",
        "            print(f\"  Completed Tasks: {status['completed_tasks']}\")\n",
        "            print(f\"  Current Tasks: {status['current_tasks']}\")\n",
        "            print(f\"  CPU Utilization: {status['cpu_utilization']:.2f}%\")\n",
        "            print(f\"  Memory Utilization: {status['memory_utilization']:.2f}%\")\n",
        "\n",
        "        # Performance metrics\n",
        "        print(\"\\nOverall Performance Metrics:\")\n",
        "        print(f\"Makespan: {metrics['makespan']:.2f} seconds\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Simulation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X9ar_Wc5VSh9",
        "outputId": "cebfa7e8-c685-41b0-e601-e11b4a038fc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m          Task Distribution           \u001b[0m\n",
              "┏━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mResource   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTasks\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFailed Tasks\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_2     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_3     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_4     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_5     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_6     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_7     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_8     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_9     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_10    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRaspberry_1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRaspberry_2\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRaspberry_3\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRaspberry_4\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mRaspberry_5\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCloud_1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCloud_2    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCloud_3    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCloud_4    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCloud_5    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m75   \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "└─────────────┴───────┴──────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">          Task Distribution           </span>\n",
              "┏━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Resource    </span>┃<span style=\"font-weight: bold\"> Tasks </span>┃<span style=\"font-weight: bold\"> Failed Tasks </span>┃\n",
              "┡━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_2      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_3      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_4      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_5      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_6      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_7      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_8      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_9      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_10     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Raspberry_1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Raspberry_2 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Raspberry_3 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Raspberry_4 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Raspberry_5 </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cloud_1     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cloud_2     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cloud_3     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cloud_4     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cloud_5     </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 75    </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "└─────────────┴───────┴──────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Simulation Metrics ---\n",
            "Total Tasks Generated: 1500\n",
            "Completed Tasks: 1500\n",
            "Failed Tasks: 0\n",
            "\n",
            "Task Distribution:\n",
            "Edge_1: 75\n",
            "Edge_2: 75\n",
            "Edge_3: 75\n",
            "Edge_4: 75\n",
            "Edge_5: 75\n",
            "Edge_6: 75\n",
            "Edge_7: 75\n",
            "Edge_8: 75\n",
            "Edge_9: 75\n",
            "Edge_10: 75\n",
            "Raspberry_1: 75\n",
            "Raspberry_2: 75\n",
            "Raspberry_3: 75\n",
            "Raspberry_4: 75\n",
            "Raspberry_5: 75\n",
            "Cloud_1: 75\n",
            "Cloud_2: 75\n",
            "Cloud_3: 75\n",
            "Cloud_4: 75\n",
            "Cloud_5: 75\n",
            "\n",
            "Resource Performance Details:\n",
            "\n",
            "Resource 1 - Edge_1:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 2 - Edge_2:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 3 - Edge_3:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 4 - Edge_4:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 5 - Edge_5:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 6 - Edge_6:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 7 - Edge_7:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 8 - Edge_8:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 9 - Edge_9:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 10 - Edge_10:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 11 - Raspberry_1:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 12 - Raspberry_2:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 13 - Raspberry_3:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 14 - Raspberry_4:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 15 - Raspberry_5:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 16 - Cloud_1:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 17 - Cloud_2:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 18 - Cloud_3:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 19 - Cloud_4:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Resource 20 - Cloud_5:\n",
            "  Completed Tasks: 75\n",
            "  Current Tasks: 0\n",
            "  CPU Utilization: 0.00%\n",
            "  Memory Utilization: 0.00%\n",
            "\n",
            "Overall Performance Metrics:\n",
            "Makespan: 9.29 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With CPU and Utilization output included"
      ],
      "metadata": {
        "id": "FTKFBZBto2q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.layout import Layout\n",
        "from rich.live import Live\n",
        "from rich.text import Text\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 data_size: float,     # in MB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = self.details.get('task_name', f'Task_{task_id}')\n",
        "        self.size = self.details.get('size', 'unspecified')\n",
        "        self.type = self.details.get('type', 'unknown')\n",
        "        self.task_class = self.details.get('task_class', 'generic')\n",
        "        self.cpu_intensity = self.details.get('cpu_intensity', 'medium')\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with comprehensive tracking and utilization metrics\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int):    # in MB/s\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.total_memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Utilization tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.current_memory_usage = 0\n",
        "\n",
        "        # Additional tracking for more nuanced CPU utilization\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue\n",
        "        \"\"\"\n",
        "        task.queue_position = len(self.task_queue)\n",
        "        self.task_queue.append(task)\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking and utilization update\n",
        "        \"\"\"\n",
        "        # Reset current usage and task tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "        # Calculate available CPU for this time step\n",
        "        available_cpu = self.cpu_rating\n",
        "\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            # Determine how much CPU can be used for this task\n",
        "            task_cpu = min(available_cpu, task.remaining_cpu)\n",
        "\n",
        "            processing_result = task.process(task_cpu)\n",
        "\n",
        "            # Update CPU usage and available CPU\n",
        "            processed_amount = processing_result['processed']\n",
        "            self.current_cpu_usage += processed_amount\n",
        "            available_cpu -= processed_amount\n",
        "\n",
        "            # Track detailed task information\n",
        "            task_info = {\n",
        "                'id': task.id,\n",
        "                'name': task.task_name,\n",
        "                'processed': processed_amount,\n",
        "                'total_required': task.total_cpu_required,\n",
        "                'completion_percentage': processing_result['completion_percentage']\n",
        "            }\n",
        "            self.detailed_task_tracking.append(task_info)\n",
        "\n",
        "            # Calculate task CPU demand\n",
        "            task_demand = processed_amount / self.cpu_rating\n",
        "            self.task_cpu_demands.append(task_demand)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "\n",
        "            # Stop processing if no CPU left\n",
        "            if available_cpu <= 0:\n",
        "                break\n",
        "\n",
        "        # Calculate CPU utilization\n",
        "        # Use sum of task CPU demands to get a more dynamic representation\n",
        "        if self.task_cpu_demands:\n",
        "            cpu_utilization = min(sum(self.task_cpu_demands) * 100, 100)\n",
        "        else:\n",
        "            cpu_utilization = 0\n",
        "\n",
        "        # Estimate memory usage (simple model: each current task uses some memory)\n",
        "        self.current_memory_usage = len(self.current_tasks) * (self.total_memory / 10)\n",
        "        memory_utilization = min((self.current_memory_usage / self.total_memory) * 100, 100)\n",
        "\n",
        "        # If resource has available capacity, move tasks from queue to current tasks\n",
        "        while self.task_queue and len(self.current_tasks) < 5:  # Limit concurrent tasks\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "\n",
        "        # Return detailed resource state with utilization\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'cpu_utilization': cpu_utilization,\n",
        "            'memory_utilization': memory_utilization,\n",
        "            'raw_cpu_usage': self.current_cpu_usage,\n",
        "            'task_demands': self.task_cpu_demands,\n",
        "            'detailed_tasks': self.detailed_task_tracking\n",
        "        }\n",
        "\n",
        "class ResourceFocusedScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with resource-focused real-time visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.current_time = 0\n",
        "        self.console = Console()\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'resource_status': {}\n",
        "        }\n",
        "\n",
        "    def load_tasks_from_json(self, json_path: str) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Load tasks from JSON\n",
        "        \"\"\"\n",
        "        with open(json_path, 'r') as f:\n",
        "            task_data = json.load(f)\n",
        "\n",
        "        tasks_list = task_data.get('tasks', [])\n",
        "\n",
        "        tasks = []\n",
        "        for task_dict in tasks_list:\n",
        "            task = Task(\n",
        "                task_id=task_dict.get('id', len(tasks) + 1),\n",
        "                data_size=task_dict.get('data_size', 10),\n",
        "                cpu_required=task_dict.get('instructions', 50000),\n",
        "                task_details=task_dict\n",
        "            )\n",
        "            task.arrival_time = self.current_time\n",
        "            tasks.append(task)\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def distribute_tasks(self):\n",
        "        \"\"\"\n",
        "        Distribute tasks across resources\n",
        "        \"\"\"\n",
        "        # Load tasks\n",
        "        tasks = self.load_tasks_from_json(\n",
        "            '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\n",
        "        )\n",
        "        self.metrics['total_tasks'] = len(tasks)\n",
        "\n",
        "        # Track task distribution\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Round-robin distribution\n",
        "        resource_index = 0\n",
        "        for task in tasks:\n",
        "            resource = self.resources[resource_index]\n",
        "            resource.enqueue_task(task)\n",
        "            task_distribution[resource.type] += 1\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        # Print distribution table\n",
        "        distribution_table = Table(title=\"Task Distribution\")\n",
        "        distribution_table.add_column(\"Resource\", style=\"cyan\")\n",
        "        distribution_table.add_column(\"Tasks\", style=\"magenta\")\n",
        "\n",
        "        for resource_type, count in task_distribution.items():\n",
        "            distribution_table.add_row(resource_type, str(count))\n",
        "\n",
        "        self.console.print(distribution_table)\n",
        "\n",
        "    def run_simulation(self, max_iterations: int = 10000):\n",
        "        \"\"\"\n",
        "        Run simulation with a stopping criterion similar to the provided code\n",
        "        \"\"\"\n",
        "        # Distribute tasks\n",
        "        self.distribute_tasks()\n",
        "\n",
        "        # Total number of tasks\n",
        "        total_tasks = self.metrics['total_tasks']\n",
        "\n",
        "        # Prepare layout for live visualization\n",
        "        layout = Layout()\n",
        "        layout.split_row(\n",
        "            Layout(name=\"resource1\"),\n",
        "            Layout(name=\"resource2\"),\n",
        "            Layout(name=\"resource3\")\n",
        "        )\n",
        "\n",
        "        # Live visualization\n",
        "        with Live(layout, console=self.console, refresh_per_second=10) as live:\n",
        "            for iteration in range(max_iterations):\n",
        "                self.current_time += 1\n",
        "\n",
        "                # Process tasks on each resource\n",
        "                for i, resource in enumerate(self.resources, 1):\n",
        "                    # Process resource queue\n",
        "                    resource_status = resource.process_queue(self.current_time)\n",
        "\n",
        "                    # Update layout with resource-specific panel\n",
        "                    layout[f\"resource{i}\"].update(\n",
        "                        self._create_resource_panel(resource, resource_status)\n",
        "                    )\n",
        "\n",
        "                # Update live display\n",
        "                live.update(layout)\n",
        "\n",
        "                # Custom stopping criterion similar to the provided code\n",
        "                provisioned_tasks = sum(\n",
        "                    len(resource.completed_tasks) for resource in self.resources\n",
        "                )\n",
        "\n",
        "                # Stop when all tasks are provisioned (completed)\n",
        "                if provisioned_tasks == total_tasks:\n",
        "                    logger.info(f\"Simulation completed in {iteration} iterations\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "        return self.metrics\n",
        "\n",
        "    def _create_resource_panel(self, resource: Resource, status: Dict) -> Panel:\n",
        "        \"\"\"\n",
        "        Create a detailed panel for a specific resource with utilization metrics\n",
        "        \"\"\"\n",
        "        # Create table for resource details\n",
        "        table = Table(show_header=False)\n",
        "\n",
        "        # Resource basic information\n",
        "        table.add_row(\"[bold]Resource Details[/bold]\")\n",
        "        table.add_row(f\"[cyan]Type:[/cyan] {resource.type}\")\n",
        "        table.add_row(f\"[green]CPU Rating:[/green] {resource.cpu_rating} MI/s\")\n",
        "        table.add_row(f\"[blue]Memory:[/blue] {resource.total_memory} GB\")\n",
        "        table.add_row(f\"[yellow]Bandwidth:[/yellow] {resource.bandwidth} MB/s\")\n",
        "\n",
        "        # Utilization information\n",
        "        table.add_row(\"\\n[bold]Utilization Metrics[/bold]\")\n",
        "        table.add_row(\n",
        "            f\"[green]CPU Usage:[/green] {status['cpu_utilization']:.2f}% \"\n",
        "            f\"({status['raw_cpu_usage']:.2f}/{resource.cpu_rating} MI/s)\"\n",
        "        )\n",
        "\n",
        "        # Show individual task demands for more insight\n",
        "        if status['task_demands']:\n",
        "            demands_str = \", \".join([f\"{d*100:.2f}%\" for d in status['task_demands']])\n",
        "            table.add_row(f\"[yellow]Task Demands:[/yellow] {demands_str}\")\n",
        "\n",
        "        # Detailed task tracking\n",
        "        if status['detailed_tasks']:\n",
        "            table.add_row(\"\\n[bold]Current Tasks[/bold]\")\n",
        "            for task in status['detailed_tasks']:\n",
        "                table.add_row(\n",
        "                    f\"[blue]Task {task['id']} ({task['name']}):[/blue] \"\n",
        "                    f\"{task['processed']:.2f}/{task['total_required']} MI \"\n",
        "                    f\"({task['completion_percentage']:.2f}%)\"\n",
        "                )\n",
        "\n",
        "        table.add_row(\n",
        "            f\"[blue]Memory Usage:[/blue] {status['memory_utilization']:.2f}% \"\n",
        "            f\"({resource.current_memory_usage:.2f}/{resource.total_memory} GB)\"\n",
        "        )\n",
        "\n",
        "        # Task processing status\n",
        "        table.add_row(\"\\n[bold]Task Processing[/bold]\")\n",
        "        table.add_row(f\"[green]Completed Tasks:[/green] {status['completed_tasks']}\")\n",
        "        table.add_row(f\"[yellow]Current Tasks:[/yellow] {status['current_tasks']}\")\n",
        "        table.add_row(f\"[red]Queue Length:[/red] {status['queue_length']}\")\n",
        "\n",
        "        # Create panel with resource-specific styling\n",
        "        return Panel(\n",
        "            table,\n",
        "            title=f\"Resource {resource.id}: {resource.type}\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "\n",
        "def create_original_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    # Create resources\n",
        "    resources = create_original_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = ResourceFocusedScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    metrics = scheduler.run_simulation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "HmJFZgwjo8uc",
        "outputId": "297309e5-00fb-46ff-87fb-4b891dadfba5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-89422f6e8375>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-89422f6e8375>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# Run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-89422f6e8375>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(self, max_iterations)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# Distribute tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Total number of tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-89422f6e8375>\u001b[0m in \u001b[0;36mdistribute_tasks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Load tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         tasks = self.load_tasks_from_json(\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;34m'/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-12-89422f6e8375>\u001b[0m in \u001b[0;36mload_tasks_from_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mLoad\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mJSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mtask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Round Robin Algorithm\n"
      ],
      "metadata": {
        "id": "qlju10qbKZWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.layout import Layout\n",
        "from rich.live import Live\n",
        "from rich.text import Text\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 task_type: str,\n",
        "                 data_size: float,     # in GB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.type = task_type\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = f\"{task_type}_Task_{task_id}\"\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with comprehensive tracking and utilization metrics\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int,     # in MB/s\n",
        "                 num_cpus: int = 1):  # Number of CPUs, defaulting to 1\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.total_memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # CPU configuration\n",
        "        self.num_cpus = num_cpus\n",
        "        self.available_cpus = num_cpus\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Utilization tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.current_memory_usage = 0\n",
        "\n",
        "        # Additional tracking\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "    def can_process_task(self, task: Task) -> bool:\n",
        "        \"\"\"\n",
        "        Check if the resource can process the given task\n",
        "        \"\"\"\n",
        "        # Check if CPUs are available\n",
        "        if self.available_cpus <= 0:\n",
        "            return False\n",
        "\n",
        "        # Cloud host can process all task types\n",
        "        if self.type == \"Cloud_Host\":\n",
        "            return True\n",
        "\n",
        "        # Edge nodes (Raspberry Pi and Smartphone) can only process RT2 tasks\n",
        "        if self.type in [\"Edge_Raspberry_Pi\", \"Edge_Smartphone\"]:\n",
        "            # Explicitly fail RT1 and RT3 tasks on edge resources\n",
        "            if task.type in [\"RT1\", \"RT3\"]:\n",
        "                logger.warning(f\"Task {task.id} of type {task.type} FAILED on {self.type}\")\n",
        "                return False\n",
        "\n",
        "            # Additional memory check for RT2 tasks\n",
        "            if task.data_size > self.total_memory:\n",
        "                logger.warning(f\"Task {task.id} requires {task.data_size} GB, exceeding {self.type}'s memory of {self.total_memory} GB\")\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue if it can be processed\n",
        "        \"\"\"\n",
        "        if self.can_process_task(task):\n",
        "            task.queue_position = len(self.task_queue)\n",
        "            task.arrival_time = time.time()\n",
        "            self.task_queue.append(task)\n",
        "        else:\n",
        "            # Mark task as failed\n",
        "            task.status = 'failed'\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking and utilization update\n",
        "        \"\"\"\n",
        "        # Reset current usage and task tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "        # Reset available CPUs\n",
        "        self.available_cpus = self.num_cpus\n",
        "\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            # Skip if no CPUs available\n",
        "            if self.available_cpus <= 0:\n",
        "                break\n",
        "\n",
        "            # Determine how much CPU can be used for this task\n",
        "            task_cpu = min(self.cpu_rating, task.remaining_cpu)\n",
        "\n",
        "            processing_result = task.process(task_cpu)\n",
        "\n",
        "            # Update CPU usage\n",
        "            processed_amount = processing_result['processed']\n",
        "            self.current_cpu_usage += processed_amount\n",
        "\n",
        "            # Track detailed task information\n",
        "            task_info = {\n",
        "                'id': task.id,\n",
        "                'name': task.task_name,\n",
        "                'type': task.type,\n",
        "                'processed': processed_amount,\n",
        "                'total_required': task.total_cpu_required,\n",
        "                'completion_percentage': processing_result['completion_percentage']\n",
        "            }\n",
        "            self.detailed_task_tracking.append(task_info)\n",
        "\n",
        "            # Calculate task CPU demand\n",
        "            task_demand = processed_amount / self.cpu_rating\n",
        "            self.task_cpu_demands.append(task_demand)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "                # Free up a CPU\n",
        "                self.available_cpus += 1\n",
        "\n",
        "        # Move tasks from queue to current tasks if CPUs are available\n",
        "        while self.task_queue and self.available_cpus > 0:\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "            # Use up a CPU\n",
        "            self.available_cpus -= 1\n",
        "\n",
        "        # Calculate CPU utilization\n",
        "        if self.task_cpu_demands:\n",
        "            cpu_utilization = min(sum(self.task_cpu_demands) * 100, 100)\n",
        "        else:\n",
        "            cpu_utilization = 0\n",
        "\n",
        "        # Estimate memory usage\n",
        "        self.current_memory_usage = len(self.current_tasks) * (self.total_memory / 10)\n",
        "        memory_utilization = min((self.current_memory_usage / self.total_memory) * 100, 100)\n",
        "\n",
        "        # Return detailed resource state with utilization\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'cpu_utilization': cpu_utilization,\n",
        "            'memory_utilization': memory_utilization,\n",
        "            'raw_cpu_usage': self.current_cpu_usage,\n",
        "            'task_demands': self.task_cpu_demands,\n",
        "            'detailed_tasks': self.detailed_task_tracking,\n",
        "            'available_cpus': self.available_cpus\n",
        "        }\n",
        "\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources with 10 Smartphones, 5 Raspberry Pis, and 5 Cloud Hosts\n",
        "    \"\"\"\n",
        "    resources = []\n",
        "\n",
        "    # Create 10 Smartphone Edge Nodes\n",
        "    for i in range(1, 11):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i,\n",
        "                resource_type=f\"Edge_{i}\",\n",
        "                cpu_rating=400000,   # 400,000 MI/s\n",
        "                memory=4,            # 4 GB\n",
        "                bandwidth=20         # 20 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Raspberry Pi Edge Nodes\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+10,  # IDs 11-15\n",
        "                resource_type=f\"Raspberry_{i}\",\n",
        "                cpu_rating=80000,    # 80,000 MI/s\n",
        "                memory=1,            # 1 GB\n",
        "                bandwidth=5          # 5 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Cloud Hosts\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+15,  # IDs 16-20\n",
        "                resource_type=f\"Cloud_{i}\",\n",
        "                cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "                memory=32,           # 32 GB\n",
        "                bandwidth=80         # 80 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return resources\n",
        "\n",
        "class ResourceFocusedScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with resource-focused real-time visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.current_time = 0\n",
        "        self.console = Console()\n",
        "\n",
        "        # Poisson process parameters\n",
        "        self.arrival_rate = 0.8  # λ = 0.8 tasks per second\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'completed_tasks': 0,\n",
        "            'failed_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'makespan': 0,\n",
        "            'throughput': 0\n",
        "        }\n",
        "\n",
        "    def generate_tasks(self, simulation_time: float = 100) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Generate tasks using Poisson process\n",
        "        \"\"\"\n",
        "        # Task types and their characteristics based on the paper\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"data_size\": 5.0, \"cpu_required\": 2_000_000},   # CPU-intensive, memory-intensive\n",
        "            {\"type\": \"RT2\", \"data_size\": 0.2, \"cpu_required\": 4_000_000},   # CPU-intensive, memory-light\n",
        "            {\"type\": \"RT3\", \"data_size\": 5.0, \"cpu_required\": 200_000},     # CPU-light, memory-intensive\n",
        "            {\"type\": \"RT4\", \"data_size\": 0.5, \"cpu_required\": 500_000}      # CPU-light, memory-light\n",
        "        ]\n",
        "\n",
        "        # Generate task arrival times using Poisson process\n",
        "        num_tasks = np.random.poisson(self.arrival_rate * simulation_time)\n",
        "\n",
        "        tasks = []\n",
        "        for i in range(num_tasks):\n",
        "            # Randomly select task type\n",
        "            task_type_data = np.random.choice(task_types)\n",
        "\n",
        "            task = Task(\n",
        "                task_id=i+1,\n",
        "                task_type=task_type_data['type'],\n",
        "                data_size=task_type_data['data_size'],\n",
        "                cpu_required=task_type_data['cpu_required']\n",
        "            )\n",
        "\n",
        "            # Set arrival time\n",
        "            task.arrival_time = np.random.uniform(0, simulation_time)\n",
        "\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Sort tasks by arrival time\n",
        "        return sorted(tasks, key=lambda x: x.arrival_time)\n",
        "\n",
        "    def distribute_tasks(self, total_tasks: int = 1500) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Generate and distribute a fixed number of tasks\n",
        "        \"\"\"\n",
        "        # Task types and their characteristics based on the paper\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"data_size\": 5.0, \"cpu_required\": 2_000_000},   # CPU-intensive, memory-intensive\n",
        "            {\"type\": \"RT2\", \"data_size\": 0.2, \"cpu_required\": 4_000_000},   # CPU-intensive, memory-light\n",
        "            {\"type\": \"RT3\", \"data_size\": 5.0, \"cpu_required\": 200_000},     # CPU-light, memory-intensive\n",
        "            {\"type\": \"RT4\", \"data_size\": 0.5, \"cpu_required\": 500_000}      # CPU-light, memory-light\n",
        "        ]\n",
        "\n",
        "        # Generate tasks\n",
        "        tasks = []\n",
        "        for i in range(total_tasks):\n",
        "            # Randomly select task type\n",
        "            task_type_data = np.random.choice(task_types)\n",
        "\n",
        "            task = Task(\n",
        "                task_id=i+1,\n",
        "                task_type=task_type_data['type'],\n",
        "                data_size=task_type_data['data_size'],\n",
        "                cpu_required=task_type_data['cpu_required']\n",
        "            )\n",
        "\n",
        "            # Set arrival time with uniform distribution\n",
        "            task.arrival_time = np.random.uniform(0, 100)  # Distribute over 100 seconds\n",
        "\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Sort tasks by arrival time\n",
        "        tasks.sort(key=lambda x: x.arrival_time)\n",
        "\n",
        "        # Update metrics\n",
        "        self.metrics['total_tasks'] = total_tasks\n",
        "\n",
        "        # Define resource order as specified in the paper\n",
        "        # Order: Smartphone, Raspberry Pi, Cloud\n",
        "        resource_order = [\n",
        "            next(r for r in self.resources if r.type.startswith(\"Edge_\")),\n",
        "            next(r for r in self.resources if r.type.startswith(\"Raspberry_\")),\n",
        "            next(r for r in self.resources if r.type.startswith(\"Cloud_\"))\n",
        "        ]\n",
        "\n",
        "\n",
        "        # Track task distribution and failures\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "        failed_tasks_by_resource = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Circular resource selection\n",
        "        resource_index = 0\n",
        "        num_resources = len(resource_order)\n",
        "\n",
        "        for task in tasks:\n",
        "            # Select resource in the specified order\n",
        "            resource = resource_order[resource_index]\n",
        "\n",
        "            # Attempt to enqueue task\n",
        "            if resource.can_process_task(task):\n",
        "                resource.enqueue_task(task)\n",
        "                task_distribution[resource.type] += 1\n",
        "            else:\n",
        "                # Increment failed tasks for the specific resource type\n",
        "                failed_tasks_by_resource[resource.type] += 1\n",
        "                self.metrics['failed_tasks'] += 1\n",
        "\n",
        "            # Move to next resource in circular manner\n",
        "            resource_index = (resource_index + 1) % num_resources\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        # Print distribution table\n",
        "        distribution_table = Table(title=\"Task Distribution\")\n",
        "        distribution_table.add_column(\"Resource\", style=\"cyan\")\n",
        "        distribution_table.add_column(\"Tasks\", style=\"magenta\")\n",
        "        distribution_table.add_column(\"Failed Tasks\", style=\"red\")\n",
        "\n",
        "        for resource_type in task_distribution:\n",
        "            distribution_table.add_row(\n",
        "                resource_type,\n",
        "                str(task_distribution[resource_type]),\n",
        "                str(failed_tasks_by_resource[resource_type])\n",
        "            )\n",
        "\n",
        "        self.console.print(distribution_table)\n",
        "\n",
        "        return tasks\n",
        "    def run_simulation(self, total_tasks: int = 1500, max_iterations: int = 10000):\n",
        "            \"\"\"\n",
        "            Run simulation with a fixed number of tasks\n",
        "            \"\"\"\n",
        "            # Record start time\n",
        "            self.start_time = time.time()\n",
        "\n",
        "            # Distribute tasks\n",
        "            tasks = self.distribute_tasks(total_tasks)\n",
        "\n",
        "            # Prepare layout for live visualization\n",
        "            layout = Layout()\n",
        "            layout.split_row(\n",
        "                Layout(name=\"resource1\"),\n",
        "                Layout(name=\"resource2\"),\n",
        "                Layout(name=\"resource3\")\n",
        "            )\n",
        "\n",
        "            # Live visualization\n",
        "            with Live(layout, console=self.console, refresh_per_second=10) as live:\n",
        "                for iteration in range(max_iterations):\n",
        "                    # Calculate current simulation time\n",
        "                    current_simulation_time = time.time() - self.start_time\n",
        "\n",
        "                    # Process tasks on each resource\n",
        "                    for i, resource in enumerate(self.resources, 1):\n",
        "                        # Process resource queue\n",
        "                        resource_status = resource.process_queue(current_simulation_time)\n",
        "\n",
        "                        # Update layout with resource-specific panel\n",
        "                        layout[f\"resource{i}\"].update(\n",
        "                            self._create_resource_panel(resource, resource_status)\n",
        "                        )\n",
        "\n",
        "                    # Update live display\n",
        "                    live.update(layout)\n",
        "\n",
        "                    # Track completed and failed tasks across all resources\n",
        "                    total_processed_tasks = sum(\n",
        "                        len(resource.completed_tasks) for resource in self.resources\n",
        "                    ) + self.metrics['failed_tasks']\n",
        "\n",
        "                    # Check if all tasks are processed (completed or failed)\n",
        "                    if total_processed_tasks >= total_tasks:\n",
        "                        logger.info(f\"Simulation completed in {iteration} iterations\")\n",
        "                        break\n",
        "\n",
        "                    time.sleep(0.1)\n",
        "\n",
        "            # Calculate final metrics\n",
        "            completed_tasks = sum(len(resource.completed_tasks) for resource in self.resources)\n",
        "            self.metrics['completed_tasks'] = completed_tasks\n",
        "            self.metrics['makespan'] = time.time() - self.start_time\n",
        "\n",
        "            return self.metrics\n",
        "    def _create_resource_panel(self, resource: Resource, status: Dict) -> Panel:\n",
        "        \"\"\"\n",
        "        Create a detailed panel for a specific resource with utilization metrics\n",
        "        \"\"\"\n",
        "        # Create table for resource details\n",
        "        table = Table(show_header=False)\n",
        "\n",
        "        # Resource basic information\n",
        "        table.add_row(\"[bold]Resource Details[/bold]\")\n",
        "        table.add_row(f\"[cyan]Type:[/cyan] {resource.type}\")\n",
        "        table.add_row(f\"[green]CPU Rating:[/green] {resource.cpu_rating} MI/s\")\n",
        "        table.add_row(f\"[blue]Memory:[/blue] {resource.total_memory} GB\")\n",
        "        table.add_row(f\"[yellow]Bandwidth:[/yellow] {resource.bandwidth} MB/s\")\n",
        "\n",
        "        # Utilization information\n",
        "        table.add_row(\"\\n[bold]Utilization Metrics[/bold]\")\n",
        "        table.add_row(\n",
        "            f\"[green]CPU Usage:[/green] {status['cpu_utilization']:.2f}% \"\n",
        "            f\"({status['raw_cpu_usage']:.2f}/{resource.cpu_rating} MI/s)\"\n",
        "        )\n",
        "\n",
        "        # Detailed task tracking\n",
        "        if status['detailed_tasks']:\n",
        "            table.add_row(\"\\n[bold]Current Tasks[/bold]\")\n",
        "            for task in status['detailed_tasks']:\n",
        "                table.add_row(                f\"[blue]Task {task['id']} ({task['type']}):[/blue] \"\n",
        "                f\"Processed {task['processed']:.2f}/{task['total_required']} MI \"\n",
        "                f\"({task['completion_percentage']:.2f}%)\"\n",
        "                )\n",
        "\n",
        "        table.add_row(\n",
        "            f\"[blue]Memory Usage:[/blue] {status['memory_utilization']:.2f}% \"\n",
        "            f\"({resource.current_memory_usage:.2f}/{resource.total_memory} GB)\"\n",
        "        )\n",
        "\n",
        "        # Task processing status\n",
        "        table.add_row(\"\\n[bold]Task Processing[/bold]\")\n",
        "        table.add_row(f\"[green]Completed Tasks:[/green] {status['completed_tasks']}\")\n",
        "        table.add_row(f\"[yellow]Current Tasks:[/yellow] {status['current_tasks']}\")\n",
        "        table.add_row(f\"[red]Queue Length:[/red] {status['queue_length']}\")\n",
        "\n",
        "        # Create panel with resource-specific styling\n",
        "        return Panel(\n",
        "            table,\n",
        "            title=f\"Resource {resource.id}: {resource.type}\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main simulation entry point\n",
        "    \"\"\"\n",
        "    # Create resources\n",
        "    resources = create_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = ResourceFocusedScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    try:\n",
        "        # Run simulation for 1500 tasks\n",
        "        metrics = scheduler.run_simulation(total_tasks=1500)\n",
        "\n",
        "        # Print final metrics\n",
        "        print(\"\\n--- Simulation Metrics ---\")\n",
        "        print(f\"Total Tasks Generated: {metrics['total_tasks']}\")\n",
        "        print(f\"Completed Tasks: {metrics['completed_tasks']}\")\n",
        "        print(f\"Failed Tasks: {metrics['failed_tasks']}\")\n",
        "        print(\"\\nTask Distribution:\")\n",
        "        for resource_type, count in metrics['task_distribution'].items():\n",
        "            print(f\"{resource_type}: {count}\")\n",
        "\n",
        "        print(\"\\nPerformance Metrics:\")\n",
        "        print(f\"Makespan: {metrics['makespan']:.2f} seconds\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Simulation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnRDGSuPKeLC",
        "outputId": "195d7b6b-4b8d-4100-9599-00d9d53df7d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Simulation failed: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-15-deedc9f6bcd8>\", line 570, in main\n",
            "    metrics = scheduler.run_simulation(total_tasks=1500)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-15-deedc9f6bcd8>\", line 429, in run_simulation\n",
            "    tasks = self.distribute_tasks(total_tasks)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-15-deedc9f6bcd8>\", line 374, in distribute_tasks\n",
            "    next(r for r in self.resources if r.type.startswith(\"Raspberry_\")),\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "StopIteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files Categories"
      ],
      "metadata": {
        "id": "KXe0GrhRY1QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "# Task Specifications\n",
        "TASK_SPECS = {\n",
        "    # Read Tasks\n",
        "    'RT1': {\n",
        "        'instructions': 2_000_000,\n",
        "        'data_size': 5,\n",
        "        'description': 'CPU-intensive, memory-intensive',\n",
        "        'example': 'Financial modeling based on large historical dataset'\n",
        "    },\n",
        "    'RT2': {\n",
        "        'instructions': 4_000_000,\n",
        "        'data_size': 0.2,\n",
        "        'description': 'CPU-intensive, memory-light',\n",
        "        'example': 'Computation of NP-hard optimization problem'\n",
        "    },\n",
        "    'RT3': {\n",
        "        'instructions': 200_000,\n",
        "        'data_size': 5,\n",
        "        'description': 'CPU-light, memory-intensive',\n",
        "        'example': 'Light database queries on large in-memory dataset'\n",
        "    },\n",
        "    'RT4': {\n",
        "        'instructions': 500_000,\n",
        "        'data_size': 0.5,\n",
        "        'description': 'CPU-light, memory-light',\n",
        "        'example': 'Light video editing'\n",
        "    },\n",
        "    # Write Tasks\n",
        "    'WT1': {\n",
        "        'instructions': 2_000_000,\n",
        "        'data_size': 2,\n",
        "        'description': 'CPU-intensive, I/O-intensive',\n",
        "        'example': 'Complex data write operations'\n",
        "    },\n",
        "    'WT2': {\n",
        "        'instructions': 1_000_000,\n",
        "        'data_size': 0.5,\n",
        "        'description': 'CPU-intensive, I/O-light',\n",
        "        'example': 'Streamlined data writing'\n",
        "    },\n",
        "    'WT3': {\n",
        "        'instructions': 500_000,\n",
        "        'data_size': 5,\n",
        "        'description': 'CPU-light, I/O-intensive',\n",
        "        'example': 'Bulk data transfer'\n",
        "    },\n",
        "    'WT4': {\n",
        "        'instructions': 200_000,\n",
        "        'data_size': 0.2,\n",
        "        'description': 'CPU-light, I/O-light',\n",
        "        'example': 'Simple data logging'\n",
        "    }\n",
        "}\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Enhanced Task class with precise categorization\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 data_size: float,     # in MB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Detailed metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = self.details.get('task_name', f'Task_{task_id}')\n",
        "        self.size = self.details.get('size', 'unspecified')\n",
        "        self.type = self.details.get('type', 'unknown')\n",
        "\n",
        "        # Precise task category identification\n",
        "        self.task_category = self._identify_precise_category()\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "    def _identify_precise_category(self) -> str:\n",
        "        \"\"\"\n",
        "        Identify precise task category based on specifications\n",
        "        \"\"\"\n",
        "        for category, spec in TASK_SPECS.items():\n",
        "            if (abs(self.total_cpu_required - spec['instructions']) < 1000 and\n",
        "                abs(self.data_size - spec['data_size']) < 0.1):\n",
        "                return category\n",
        "        return 'Uncategorized'\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with advanced task tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int):    # in MB/s\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # Advanced task tracking\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Detailed task categorization tracking\n",
        "        self.task_category_counts = defaultdict(int)\n",
        "        self.queue_category_counts = defaultdict(int)\n",
        "        self.task_details = defaultdict(lambda: {\n",
        "            'total_instr': 0,\n",
        "            'total_data_size': 0.0,\n",
        "            'description': '',\n",
        "            'example': ''\n",
        "        })\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue with detailed categorization\n",
        "        \"\"\"\n",
        "        task.queue_position = len(self.task_queue)\n",
        "        self.task_queue.append(task)\n",
        "        self.queue_category_counts[task.task_category] += 1\n",
        "\n",
        "        # Track task details\n",
        "        category = task.task_category\n",
        "        if category in TASK_SPECS:\n",
        "            spec = TASK_SPECS[category]\n",
        "            self.task_details[category]['total_instr'] += task.total_cpu_required\n",
        "            self.task_details[category]['total_data_size'] += task.data_size\n",
        "            self.task_details[category]['description'] = spec['description']\n",
        "            self.task_details[category]['example'] = spec['example']\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks with detailed categorization\n",
        "        \"\"\"\n",
        "        # Process current tasks\n",
        "        for task in self.current_tasks[:]:\n",
        "            processing_result = task.process(self.cpu_rating)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "\n",
        "                # Track completed task category\n",
        "                self.task_category_counts[task.task_category] += 1\n",
        "\n",
        "        # Move tasks from queue to current tasks\n",
        "        while self.task_queue and len(self.current_tasks) < 5:\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "\n",
        "            # Decrement queue category count\n",
        "            self.queue_category_counts[next_task.task_category] -= 1\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'completed_categories': dict(self.task_category_counts),\n",
        "            'queue_categories': {k: v for k, v in self.queue_category_counts.items() if v > 0}\n",
        "        }\n",
        "\n",
        "class DetailedTaskScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with comprehensive task categorization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.console = Console()\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "        }\n",
        "\n",
        "    def load_tasks_from_json(self, json_path: str) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Load tasks with comprehensive parsing\n",
        "        \"\"\"\n",
        "        with open(json_path, 'r') as f:\n",
        "            task_data = json.load(f)\n",
        "\n",
        "        tasks_list = task_data.get('tasks', [])\n",
        "\n",
        "        tasks = []\n",
        "        for task_dict in tasks_list:\n",
        "            task = Task(\n",
        "                task_id=task_dict.get('id', len(tasks) + 1),\n",
        "                data_size=task_dict.get('data_size', 10),\n",
        "                cpu_required=task_dict.get('instructions', 50000),\n",
        "                task_details=task_dict\n",
        "            )\n",
        "            tasks.append(task)\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def distribute_tasks(self):\n",
        "        \"\"\"\n",
        "        Distribute tasks across resources with categorization\n",
        "        \"\"\"\n",
        "        # Load tasks\n",
        "        tasks = self.load_tasks_from_json(\n",
        "            '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\n",
        "        )\n",
        "        self.metrics['total_tasks'] = len(tasks)\n",
        "\n",
        "        # Track task distribution\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Round-robin distribution\n",
        "        resource_index = 0\n",
        "        for task in tasks:\n",
        "            resource = self.resources[resource_index]\n",
        "            resource.enqueue_task(task)\n",
        "            task_distribution[resource.type] += 1\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def run_simulation(self, max_iterations: int = 1000):\n",
        "        \"\"\"\n",
        "        Run simulation and track task categorization\n",
        "        \"\"\"\n",
        "        # Distribute tasks\n",
        "        self.distribute_tasks()\n",
        "\n",
        "        # Process tasks\n",
        "        for _ in range(max_iterations):\n",
        "            all_completed = True\n",
        "\n",
        "            for resource in self.resources:\n",
        "                resource.process_queue(time.time())\n",
        "\n",
        "                # Check if resource still has tasks\n",
        "                if (len(resource.task_queue) > 0 or\n",
        "                    len(resource.current_tasks) > 0):\n",
        "                    all_completed = False\n",
        "\n",
        "            if all_completed:\n",
        "                break\n",
        "\n",
        "        # Generate comprehensive report\n",
        "        self.generate_final_report()\n",
        "\n",
        "    def generate_final_report(self):\n",
        "        \"\"\"\n",
        "        Generate detailed report of task processing with comprehensive information\n",
        "        \"\"\"\n",
        "        self.console.rule(\"[bold blue]Task Processing Report[/bold blue]\")\n",
        "\n",
        "        for resource in self.resources:\n",
        "            # Create table for resource\n",
        "            resource_table = Table(title=f\"Resource {resource.id}: {resource.type}\")\n",
        "            resource_table.add_column(\"Task Category\", style=\"cyan\")\n",
        "            resource_table.add_column(\"Completed Tasks\", style=\"green\")\n",
        "            resource_table.add_column(\"Remaining in Queue\", style=\"red\")\n",
        "            resource_table.add_column(\"Total Instructions (MI)\", style=\"magenta\")\n",
        "            resource_table.add_column(\"Total Data Size (GB)\", style=\"yellow\")\n",
        "            resource_table.add_column(\"Description\", style=\"blue\")\n",
        "\n",
        "            # Combine all task categories\n",
        "            all_categories = sorted(set(list(resource.task_category_counts.keys()) +\n",
        "                                 list(resource.queue_category_counts.keys())))\n",
        "\n",
        "            # Populate table\n",
        "            for category in all_categories:\n",
        "                completed = resource.task_category_counts.get(category, 0)\n",
        "                queued = resource.queue_category_counts.get(category, 0)\n",
        "\n",
        "                # Get task details\n",
        "                details = resource.task_details.get(category, {\n",
        "                    'total_instr': 0,\n",
        "                    'total_data_size': 0.0,\n",
        "                    'description': 'N/A',\n",
        "                    'example': ''\n",
        "                })\n",
        "\n",
        "                resource_table.add_row(\n",
        "                    category,\n",
        "                    str(completed),\n",
        "                    str(queued),\n",
        "                    f\"{details['total_instr']:,}\",\n",
        "                    f\"{details['total_data_size']:.2f}\",\n",
        "                    details['description']\n",
        "                )\n",
        "\n",
        "            # Print resource-specific table\n",
        "            self.console.print(resource_table)\n",
        "            self.console.print(\"\\n\")\n",
        "\n",
        "def create_original_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    # Create resources\n",
        "    resources = create_original_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = DetailedTaskScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    scheduler.run_simulation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "-ffR1_EIY31s",
        "outputId": "4cff0399-8c12-4b31-ad46-0c287cee479b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e04c8c87e35e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-e04c8c87e35e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;31m# Run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e04c8c87e35e>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(self, max_iterations)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \"\"\"\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# Distribute tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Process tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e04c8c87e35e>\u001b[0m in \u001b[0;36mdistribute_tasks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Load tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         tasks = self.load_tasks_from_json(\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;34m'/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-6-e04c8c87e35e>\u001b[0m in \u001b[0;36mload_tasks_from_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mLoad\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcomprehensive\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mtask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task Generator mixed large and small files\n"
      ],
      "metadata": {
        "id": "lgMcsRNxJeIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "class TaskGenerator:\n",
        "    def __init__(self):\n",
        "        # Detailed task configurations with more specific characteristics\n",
        "        self.task_configs = {\n",
        "            # Large Read Tasks\n",
        "            'large_read_tasks': {\n",
        "                'RT1': {\n",
        "                    'instr': 2_000_000,  # Million Instructions\n",
        "                    'data': 5,           # GB\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'memory_intensity': 'high',\n",
        "                    'task_class': 'CPU-intensive, memory-intensive'\n",
        "                },\n",
        "                'RT2': {\n",
        "                    'instr': 4_000_000,\n",
        "                    'data': 0.2,\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'memory_intensity': 'low',\n",
        "                    'task_class': 'CPU-intensive, memory-light'\n",
        "                }\n",
        "            },\n",
        "            # Large Write Tasks\n",
        "            'large_write_tasks': {\n",
        "                'WT1': {\n",
        "                    'instr': 2_000_000,\n",
        "                    'data': 2,\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'io_intensity': 'high',\n",
        "                    'task_class': 'CPU-intensive, I/O-intensive'\n",
        "                },\n",
        "                'WT2': {\n",
        "                    'instr': 1_000_000,\n",
        "                    'data': 0.5,\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'io_intensity': 'low',\n",
        "                    'task_class': 'CPU-intensive, I/O-light'\n",
        "                }\n",
        "            },\n",
        "            # Small Read Tasks\n",
        "            'small_read_tasks': {\n",
        "                'RT3': {\n",
        "                    'instr': 200_000,\n",
        "                    'data': 5,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'memory_intensity': 'high',\n",
        "                    'task_class': 'CPU-light, memory-intensive'\n",
        "                },\n",
        "                'RT4': {\n",
        "                    'instr': 500_000,\n",
        "                    'data': 0.5,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'memory_intensity': 'low',\n",
        "                    'task_class': 'CPU-light, memory-light'\n",
        "                }\n",
        "            },\n",
        "            # Small Write Tasks\n",
        "            'small_write_tasks': {\n",
        "                'WT3': {\n",
        "                    'instr': 500_000,\n",
        "                    'data': 5,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'io_intensity': 'high',\n",
        "                    'task_class': 'CPU-light, I/O-intensive'\n",
        "                },\n",
        "                'WT4': {\n",
        "                    'instr': 200_000,\n",
        "                    'data': 0.2,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'io_intensity': 'low',\n",
        "                    'task_class': 'CPU-light, I/O-light'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_large_task_set(self, total_tasks: int, large_task_percentage: float = 0.7) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate a comprehensive set of tasks with detailed categorization\n",
        "        \"\"\"\n",
        "        # Calculate number of each type\n",
        "        num_large_tasks = int(total_tasks * large_task_percentage)\n",
        "        num_small_tasks = total_tasks - num_large_tasks\n",
        "\n",
        "        # Generate tasks\n",
        "        tasks = []\n",
        "        task_id = 1\n",
        "\n",
        "        # Generate large tasks\n",
        "        large_tasks = self._generate_tasks(num_large_tasks, \"large\", task_id)\n",
        "        tasks.extend(large_tasks)\n",
        "        task_id += num_large_tasks\n",
        "\n",
        "        # Generate small tasks\n",
        "        small_tasks = self._generate_tasks(num_small_tasks, \"small\", task_id)\n",
        "        tasks.extend(small_tasks)\n",
        "\n",
        "        # Shuffle tasks to randomize their order\n",
        "        random.shuffle(tasks)\n",
        "\n",
        "        # Categorize tasks\n",
        "        categorized_tasks = self._categorize_tasks(tasks)\n",
        "\n",
        "        # Prepare task set metadata\n",
        "        task_set_metadata = {\n",
        "            \"total_tasks\": total_tasks,\n",
        "            \"large_task_percentage\": large_task_percentage,\n",
        "            \"large_tasks\": num_large_tasks,\n",
        "            \"small_tasks\": num_small_tasks,\n",
        "            \"task_distribution\": {\n",
        "                \"read_tasks\": sum(1 for task in tasks if task.get('type') == 'read'),\n",
        "                \"write_tasks\": sum(1 for task in tasks if task.get('type') == 'write')\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"metadata\": task_set_metadata,\n",
        "            \"categorized_tasks\": categorized_tasks,\n",
        "            \"raw_tasks\": tasks\n",
        "        }\n",
        "\n",
        "    def _generate_tasks(self, num_tasks: int, size: str, start_id: int) -> List[Dict]:\n",
        "        \"\"\"Generate tasks of a specific size\"\"\"\n",
        "        tasks = []\n",
        "\n",
        "        for i in range(num_tasks):\n",
        "            # Randomly choose between read and write tasks (50-50 distribution)\n",
        "            task_type = random.choice([\"read\", \"write\"])\n",
        "\n",
        "            # Get appropriate config based on size and type\n",
        "            config_key = f\"{size}_{task_type}_tasks\"\n",
        "            possible_tasks = self.task_configs[config_key]\n",
        "\n",
        "            # Randomly select a task configuration\n",
        "            task_name = random.choice(list(possible_tasks.keys()))\n",
        "            task_config = possible_tasks[task_name]\n",
        "\n",
        "            # Create task dictionary\n",
        "            task = {\n",
        "                \"id\": start_id + i,\n",
        "                \"task_name\": task_name,\n",
        "                \"size\": size,\n",
        "                \"type\": task_type,\n",
        "                \"instructions\": task_config['instr'],\n",
        "                \"data_size\": task_config['data'],\n",
        "                \"arrival_time\": random.randint(0, 1000),  # Random arrival time\n",
        "                \"status\": \"pending\",\n",
        "                **{k: v for k, v in task_config.items() if k not in ['instr', 'data']}\n",
        "            }\n",
        "            tasks.append(task)\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def _categorize_tasks(self, tasks: List[Dict]) -> Dict[str, List[Dict]]:\n",
        "        \"\"\"\n",
        "        Categorize tasks by their specific characteristics\n",
        "        \"\"\"\n",
        "        categorized = defaultdict(list)\n",
        "\n",
        "        # Categorize by task names (RT1, RT2, etc.)\n",
        "        for task in tasks:\n",
        "            categorized[task['task_name']].append(task)\n",
        "\n",
        "        return dict(categorized)\n",
        "\n",
        "def generate_and_save_task_set(total_tasks: int = 1500, large_task_percentage: float = 0.7):\n",
        "    \"\"\"\n",
        "    Generate task set, save to file, and print detailed categorization\n",
        "    \"\"\"\n",
        "    # Create task generator\n",
        "    generator = TaskGenerator()\n",
        "\n",
        "    # Generate tasks\n",
        "    task_set = generator.generate_large_task_set(\n",
        "        total_tasks=total_tasks,\n",
        "        large_task_percentage=large_task_percentage\n",
        "    )\n",
        "\n",
        "    # Print detailed categorization\n",
        "    print(\"\\n--- DETAILED TASK CATEGORIZATION ---\")\n",
        "    for task_category, tasks in task_set['categorized_tasks'].items():\n",
        "        print(f\"\\n{task_category} Tasks:\")\n",
        "        print(f\"Total {task_category} Tasks: {len(tasks)}\")\n",
        "        print(\"Sample Task Details:\")\n",
        "        for task in tasks[:3]:  # Print first 3 tasks of each category\n",
        "            print(\"\\nTask Details:\")\n",
        "            for key, value in task.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Print overall metadata\n",
        "    print(\"\\n--- TASK SET METADATA ---\")\n",
        "    print(json.dumps(task_set['metadata'], indent=2))\n",
        "\n",
        "    # Save to JSON\n",
        "    save_path = 'fcfs_task_set.json'\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(task_set, f, indent=2)\n",
        "\n",
        "    print(f\"\\nFull task set saved to: {save_path}\")\n",
        "\n",
        "    return task_set\n",
        "\n",
        "# Run the task generation\n",
        "if __name__ == \"__main__\":\n",
        "    generate_and_save_task_set()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyuPsyhrJjJw",
        "outputId": "b2a2fd3f-ed2a-40af-adea-7bae6552b53f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DETAILED TASK CATEGORIZATION ---\n",
            "\n",
            "WT1 Tasks:\n",
            "Total WT1 Tasks: 270\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 156\n",
            "task_name: WT1\n",
            "size: large\n",
            "type: write\n",
            "instructions: 2000000\n",
            "data_size: 2\n",
            "arrival_time: 401\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: high\n",
            "task_class: CPU-intensive, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 951\n",
            "task_name: WT1\n",
            "size: large\n",
            "type: write\n",
            "instructions: 2000000\n",
            "data_size: 2\n",
            "arrival_time: 637\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: high\n",
            "task_class: CPU-intensive, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 123\n",
            "task_name: WT1\n",
            "size: large\n",
            "type: write\n",
            "instructions: 2000000\n",
            "data_size: 2\n",
            "arrival_time: 52\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: high\n",
            "task_class: CPU-intensive, I/O-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "RT2 Tasks:\n",
            "Total RT2 Tasks: 253\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 462\n",
            "task_name: RT2\n",
            "size: large\n",
            "type: read\n",
            "instructions: 4000000\n",
            "data_size: 0.2\n",
            "arrival_time: 656\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: low\n",
            "task_class: CPU-intensive, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 718\n",
            "task_name: RT2\n",
            "size: large\n",
            "type: read\n",
            "instructions: 4000000\n",
            "data_size: 0.2\n",
            "arrival_time: 59\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: low\n",
            "task_class: CPU-intensive, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 1019\n",
            "task_name: RT2\n",
            "size: large\n",
            "type: read\n",
            "instructions: 4000000\n",
            "data_size: 0.2\n",
            "arrival_time: 706\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: low\n",
            "task_class: CPU-intensive, memory-light\n",
            "--------------------------------------------------\n",
            "\n",
            "WT4 Tasks:\n",
            "Total WT4 Tasks: 101\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1157\n",
            "task_name: WT4\n",
            "size: small\n",
            "type: write\n",
            "instructions: 200000\n",
            "data_size: 0.2\n",
            "arrival_time: 22\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: low\n",
            "task_class: CPU-light, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 1470\n",
            "task_name: WT4\n",
            "size: small\n",
            "type: write\n",
            "instructions: 200000\n",
            "data_size: 0.2\n",
            "arrival_time: 883\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: low\n",
            "task_class: CPU-light, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 1126\n",
            "task_name: WT4\n",
            "size: small\n",
            "type: write\n",
            "instructions: 200000\n",
            "data_size: 0.2\n",
            "arrival_time: 384\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: low\n",
            "task_class: CPU-light, I/O-light\n",
            "--------------------------------------------------\n",
            "\n",
            "RT3 Tasks:\n",
            "Total RT3 Tasks: 122\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1463\n",
            "task_name: RT3\n",
            "size: small\n",
            "type: read\n",
            "instructions: 200000\n",
            "data_size: 5\n",
            "arrival_time: 478\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: high\n",
            "task_class: CPU-light, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1311\n",
            "task_name: RT3\n",
            "size: small\n",
            "type: read\n",
            "instructions: 200000\n",
            "data_size: 5\n",
            "arrival_time: 562\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: high\n",
            "task_class: CPU-light, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1208\n",
            "task_name: RT3\n",
            "size: small\n",
            "type: read\n",
            "instructions: 200000\n",
            "data_size: 5\n",
            "arrival_time: 918\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: high\n",
            "task_class: CPU-light, memory-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "RT1 Tasks:\n",
            "Total RT1 Tasks: 258\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 999\n",
            "task_name: RT1\n",
            "size: large\n",
            "type: read\n",
            "instructions: 2000000\n",
            "data_size: 5\n",
            "arrival_time: 216\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: high\n",
            "task_class: CPU-intensive, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 219\n",
            "task_name: RT1\n",
            "size: large\n",
            "type: read\n",
            "instructions: 2000000\n",
            "data_size: 5\n",
            "arrival_time: 64\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: high\n",
            "task_class: CPU-intensive, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 338\n",
            "task_name: RT1\n",
            "size: large\n",
            "type: read\n",
            "instructions: 2000000\n",
            "data_size: 5\n",
            "arrival_time: 497\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: high\n",
            "task_class: CPU-intensive, memory-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "WT2 Tasks:\n",
            "Total WT2 Tasks: 269\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 278\n",
            "task_name: WT2\n",
            "size: large\n",
            "type: write\n",
            "instructions: 1000000\n",
            "data_size: 0.5\n",
            "arrival_time: 901\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: low\n",
            "task_class: CPU-intensive, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 629\n",
            "task_name: WT2\n",
            "size: large\n",
            "type: write\n",
            "instructions: 1000000\n",
            "data_size: 0.5\n",
            "arrival_time: 743\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: low\n",
            "task_class: CPU-intensive, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 773\n",
            "task_name: WT2\n",
            "size: large\n",
            "type: write\n",
            "instructions: 1000000\n",
            "data_size: 0.5\n",
            "arrival_time: 995\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: low\n",
            "task_class: CPU-intensive, I/O-light\n",
            "--------------------------------------------------\n",
            "\n",
            "RT4 Tasks:\n",
            "Total RT4 Tasks: 114\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1158\n",
            "task_name: RT4\n",
            "size: small\n",
            "type: read\n",
            "instructions: 500000\n",
            "data_size: 0.5\n",
            "arrival_time: 89\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: low\n",
            "task_class: CPU-light, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 1065\n",
            "task_name: RT4\n",
            "size: small\n",
            "type: read\n",
            "instructions: 500000\n",
            "data_size: 0.5\n",
            "arrival_time: 670\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: low\n",
            "task_class: CPU-light, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 1186\n",
            "task_name: RT4\n",
            "size: small\n",
            "type: read\n",
            "instructions: 500000\n",
            "data_size: 0.5\n",
            "arrival_time: 225\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: low\n",
            "task_class: CPU-light, memory-light\n",
            "--------------------------------------------------\n",
            "\n",
            "WT3 Tasks:\n",
            "Total WT3 Tasks: 113\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1252\n",
            "task_name: WT3\n",
            "size: small\n",
            "type: write\n",
            "instructions: 500000\n",
            "data_size: 5\n",
            "arrival_time: 549\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: high\n",
            "task_class: CPU-light, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1202\n",
            "task_name: WT3\n",
            "size: small\n",
            "type: write\n",
            "instructions: 500000\n",
            "data_size: 5\n",
            "arrival_time: 598\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: high\n",
            "task_class: CPU-light, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1062\n",
            "task_name: WT3\n",
            "size: small\n",
            "type: write\n",
            "instructions: 500000\n",
            "data_size: 5\n",
            "arrival_time: 930\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: high\n",
            "task_class: CPU-light, I/O-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "--- TASK SET METADATA ---\n",
            "{\n",
            "  \"total_tasks\": 1500,\n",
            "  \"large_task_percentage\": 0.7,\n",
            "  \"large_tasks\": 1050,\n",
            "  \"small_tasks\": 450,\n",
            "  \"task_distribution\": {\n",
            "    \"read_tasks\": 747,\n",
            "    \"write_tasks\": 753\n",
            "  }\n",
            "}\n",
            "\n",
            "Full task set saved to: fcfs_task_set.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1HSMks9EdDf"
      },
      "source": [
        "Once we have our stopping criterion, we can finally run our simulation by creating an instance of the `Simulator` class, loading a dataset, and calling the `run_model()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hShU1WhxEdDg",
        "outputId": "98115fcf-1658-40b5-d80d-e191cecf60d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Service_1. Host: EdgeServer_1\n",
            "Service_2. Host: EdgeServer_1\n",
            "Service_3. Host: EdgeServer_1\n",
            "Service_4. Host: EdgeServer_1\n",
            "Service_5. Host: EdgeServer_1\n",
            "Service_6. Host: EdgeServer_1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Creating a Simulator object\n",
        "simulator = Simulator(\n",
        "    tick_duration=1,\n",
        "    tick_unit=\"seconds\",\n",
        "    stopping_criterion=stopping_criterion,\n",
        "    resource_management_algorithm=my_algorithm,\n",
        ")\n",
        "\n",
        "# Loading a sample dataset from GitHub\n",
        "simulator.initialize(input_file=\"https://raw.githubusercontent.com/EdgeSimPy/edgesimpy-tutorials/master/datasets/sample_dataset2.json\")\n",
        "\n",
        "# Executing the simulation\n",
        "simulator.run_model()\n",
        "\n",
        "# Checking the placement output\n",
        "for service in Service.all():\n",
        "    print(f\"{service}. Host: {service.server}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('edgesimpy-tutorials-QsXmQ38W-py3.10')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "50cb211c4021f4a25a142368b69ce4d994f94aff73dc90314b4ffb0c06ad024a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}